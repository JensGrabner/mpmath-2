<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Docutils 0.4: http://docutils.sourceforge.net/" />
<title>Mpmath manual</title>
<meta name="author" content="Fredrik Johansson" />
<style type="text/css">

/*
:Author: David Goodger
:Contact: goodger@users.sourceforge.net
:Date: $Date: 2005-12-18 01:56:14 +0100 (Sun, 18 Dec 2005) $
:Revision: $Revision: 4224 $
:Copyright: This stylesheet has been placed in the public domain.

Default cascading style sheet for the HTML output of Docutils.

See http://docutils.sf.net/docs/howto/html-stylesheets.html for how to
customize this style sheet.
*/

/* used to remove borders from tables and images */
.borderless, table.borderless td, table.borderless th {
  border: 0 }

table.borderless td, table.borderless th {
  /* Override padding for "table.docutils td" with "! important".
     The right padding separates the table cells. */
  padding: 0 0.5em 0 0 ! important }

.first {
  /* Override more specific margin styles with "! important". */
  margin-top: 0 ! important }

.last, .with-subtitle {
  margin-bottom: 0 ! important }

.hidden {
  display: none }

a.toc-backref {
  text-decoration: none ;
  color: black }

blockquote.epigraph {
  margin: 2em 5em ; }

dl.docutils dd {
  margin-bottom: 0.5em }

/* Uncomment (and remove this text!) to get bold-faced definition list terms
dl.docutils dt {
  font-weight: bold }
*/

div.abstract {
  margin: 2em 5em }

div.abstract p.topic-title {
  font-weight: bold ;
  text-align: center }

div.admonition, div.attention, div.caution, div.danger, div.error,
div.hint, div.important, div.note, div.tip, div.warning {
  margin: 2em ;
  border: medium outset ;
  padding: 1em }

div.admonition p.admonition-title, div.hint p.admonition-title,
div.important p.admonition-title, div.note p.admonition-title,
div.tip p.admonition-title {
  font-weight: bold ;
  font-family: sans-serif }

div.attention p.admonition-title, div.caution p.admonition-title,
div.danger p.admonition-title, div.error p.admonition-title,
div.warning p.admonition-title {
  color: red ;
  font-weight: bold ;
  font-family: sans-serif }

/* Uncomment (and remove this text!) to get reduced vertical space in
   compound paragraphs.
div.compound .compound-first, div.compound .compound-middle {
  margin-bottom: 0.5em }

div.compound .compound-last, div.compound .compound-middle {
  margin-top: 0.5em }
*/

div.dedication {
  margin: 2em 5em ;
  text-align: center ;
  font-style: italic }

div.dedication p.topic-title {
  font-weight: bold ;
  font-style: normal }

div.figure {
  margin-left: 2em ;
  margin-right: 2em }

div.footer, div.header {
  clear: both;
  font-size: smaller }

div.line-block {
  display: block ;
  margin-top: 1em ;
  margin-bottom: 1em }

div.line-block div.line-block {
  margin-top: 0 ;
  margin-bottom: 0 ;
  margin-left: 1.5em }

div.sidebar {
  margin-left: 1em ;
  border: medium outset ;
  padding: 1em ;
  background-color: #ffffee ;
  width: 40% ;
  float: right ;
  clear: right }

div.sidebar p.rubric {
  font-family: sans-serif ;
  font-size: medium }

div.system-messages {
  margin: 5em }

div.system-messages h1 {
  color: red }

div.system-message {
  border: medium outset ;
  padding: 1em }

div.system-message p.system-message-title {
  color: red ;
  font-weight: bold }

div.topic {
  margin: 2em }

h1.section-subtitle, h2.section-subtitle, h3.section-subtitle,
h4.section-subtitle, h5.section-subtitle, h6.section-subtitle {
  margin-top: 0.4em }

h1.title {
  text-align: center }

h2.subtitle {
  text-align: center }

hr.docutils {
  width: 75% }

img.align-left {
  clear: left }

img.align-right {
  clear: right }

ol.simple, ul.simple {
  margin-bottom: 1em }

ol.arabic {
  list-style: decimal }

ol.loweralpha {
  list-style: lower-alpha }

ol.upperalpha {
  list-style: upper-alpha }

ol.lowerroman {
  list-style: lower-roman }

ol.upperroman {
  list-style: upper-roman }

p.attribution {
  text-align: right ;
  margin-left: 50% }

p.caption {
  font-style: italic }

p.credits {
  font-style: italic ;
  font-size: smaller }

p.label {
  white-space: nowrap }

p.rubric {
  font-weight: bold ;
  font-size: larger ;
  color: maroon ;
  text-align: center }

p.sidebar-title {
  font-family: sans-serif ;
  font-weight: bold ;
  font-size: larger }

p.sidebar-subtitle {
  font-family: sans-serif ;
  font-weight: bold }

p.topic-title {
  font-weight: bold }

pre.address {
  margin-bottom: 0 ;
  margin-top: 0 ;
  font-family: serif ;
  font-size: 100% }

pre.literal-block, pre.doctest-block {
  margin-left: 2em ;
  margin-right: 2em ;
  background-color: #eeeeee }

span.classifier {
  font-family: sans-serif ;
  font-style: oblique }

span.classifier-delimiter {
  font-family: sans-serif ;
  font-weight: bold }

span.interpreted {
  font-family: sans-serif }

span.option {
  white-space: nowrap }

span.pre {
  white-space: pre }

span.problematic {
  color: red }

span.section-subtitle {
  /* font-size relative to parent (h1..h6 element) */
  font-size: 80% }

table.citation {
  border-left: solid 1px gray;
  margin-left: 1px }

table.docinfo {
  margin: 2em 4em }

table.docutils {
  margin-top: 0.5em ;
  margin-bottom: 0.5em }

table.footnote {
  border-left: solid 1px black;
  margin-left: 1px }

table.docutils td, table.docutils th,
table.docinfo td, table.docinfo th {
  padding-left: 0.5em ;
  padding-right: 0.5em ;
  vertical-align: top }

table.docutils th.field-name, table.docinfo th.docinfo-name {
  font-weight: bold ;
  text-align: left ;
  white-space: nowrap ;
  padding-left: 0 }

h1 tt.docutils, h2 tt.docutils, h3 tt.docutils,
h4 tt.docutils, h5 tt.docutils, h6 tt.docutils {
  font-size: 100% }

tt.docutils {
  background-color: #eeeeee }

ul.auto-toc {
  list-style-type: none }

</style>
</head>
<body>
<div class="document" id="mpmath-manual">
<h1 class="title">Mpmath manual</h1>
<table class="docinfo" frame="void" rules="none">
<col class="docinfo-name" />
<col class="docinfo-content" />
<tbody valign="top">
<tr><th class="docinfo-name">Author:</th>
<td>Fredrik Johansson</td></tr>
<tr class="field"><th class="docinfo-name">E-mail:</th><td class="field-body"><a class="reference" href="mailto:fredrik.johansson&#64;gmail.com">fredrik.johansson&#64;gmail.com</a></td>
</tr>
<tr class="field"><th class="docinfo-name">Updated:</th><td class="field-body">2008-03-09</td>
</tr>
<tr class="field"><th class="docinfo-name">Mpmath version:</th><td class="field-body">0.7</td>
</tr>
</tbody>
</table>
<!-- -*- rest -*- -->
<div class="contents local topic">
<ul class="auto-toc simple">
<li><a class="reference" href="#about-mpmath" id="id1" name="id1">1&nbsp;&nbsp;&nbsp;About mpmath</a></li>
<li><a class="reference" href="#installation" id="id2" name="id2">2&nbsp;&nbsp;&nbsp;Installation</a></li>
<li><a class="reference" href="#basic-arithmetic" id="id3" name="id3">3&nbsp;&nbsp;&nbsp;Basic arithmetic</a><ul class="auto-toc">
<li><a class="reference" href="#working-with-mpmath-numbers" id="id4" name="id4">3.1&nbsp;&nbsp;&nbsp;Working with mpmath numbers</a></li>
<li><a class="reference" href="#controlling-precision" id="id5" name="id5">3.2&nbsp;&nbsp;&nbsp;Controlling precision</a><ul class="auto-toc">
<li><a class="reference" href="#temporarily-changing-the-precision" id="id6" name="id6">3.2.1&nbsp;&nbsp;&nbsp;Temporarily changing the precision</a></li>
</ul>
</li>
<li><a class="reference" href="#caveat-providing-correct-input" id="id7" name="id7">3.3&nbsp;&nbsp;&nbsp;Caveat: providing correct input</a></li>
<li><a class="reference" href="#magical-numbers" id="id8" name="id8">3.4&nbsp;&nbsp;&nbsp;Magical numbers</a></li>
<li><a class="reference" href="#mathematical-functions" id="id9" name="id9">3.5&nbsp;&nbsp;&nbsp;Mathematical functions</a></li>
</ul>
</li>
<li><a class="reference" href="#high-level-features" id="id10" name="id10">4&nbsp;&nbsp;&nbsp;High-level features</a><ul class="auto-toc">
<li><a class="reference" href="#numerical-integration" id="id11" name="id11">4.1&nbsp;&nbsp;&nbsp;Numerical integration</a><ul class="auto-toc">
<li><a class="reference" href="#features-and-application-examples" id="id12" name="id12">4.1.1&nbsp;&nbsp;&nbsp;Features and application examples</a></li>
<li><a class="reference" href="#double-integrals" id="id13" name="id13">4.1.2&nbsp;&nbsp;&nbsp;Double integrals</a></li>
<li><a class="reference" href="#error-detection" id="id14" name="id14">4.1.3&nbsp;&nbsp;&nbsp;Error detection</a></li>
</ul>
</li>
<li><a class="reference" href="#numerical-differentiation" id="id15" name="id15">4.2&nbsp;&nbsp;&nbsp;Numerical differentiation</a></li>
<li><a class="reference" href="#root-finding-with-the-secant-method" id="id16" name="id16">4.3&nbsp;&nbsp;&nbsp;Root-finding with the secant method</a><ul class="auto-toc">
<li><a class="reference" href="#simple-examples" id="id17" name="id17">4.3.1&nbsp;&nbsp;&nbsp;Simple examples</a></li>
<li><a class="reference" href="#applications" id="id18" name="id18">4.3.2&nbsp;&nbsp;&nbsp;Applications</a></li>
<li><a class="reference" href="#options" id="id19" name="id19">4.3.3&nbsp;&nbsp;&nbsp;Options</a></li>
</ul>
</li>
<li><a class="reference" href="#polynomials" id="id20" name="id20">4.4&nbsp;&nbsp;&nbsp;Polynomials</a><ul class="auto-toc">
<li><a class="reference" href="#polynomial-evaluation" id="id21" name="id21">4.4.1&nbsp;&nbsp;&nbsp;Polynomial evaluation</a></li>
<li><a class="reference" href="#finding-roots-of-polynomials" id="id22" name="id22">4.4.2&nbsp;&nbsp;&nbsp;Finding roots of polynomials</a></li>
</ul>
</li>
<li><a class="reference" href="#interval-arithmetic" id="id23" name="id23">4.5&nbsp;&nbsp;&nbsp;Interval arithmetic</a></li>
</ul>
</li>
<li><a class="reference" href="#technical-details" id="id24" name="id24">5&nbsp;&nbsp;&nbsp;Technical details</a><ul class="auto-toc">
<li><a class="reference" href="#representation-of-numbers" id="id25" name="id25">5.1&nbsp;&nbsp;&nbsp;Representation of numbers</a></li>
<li><a class="reference" href="#precision-and-accuracy" id="id26" name="id26">5.2&nbsp;&nbsp;&nbsp;Precision and accuracy</a><ul class="auto-toc">
<li><a class="reference" href="#decimal-issues" id="id27" name="id27">5.2.1&nbsp;&nbsp;&nbsp;Decimal issues</a></li>
</ul>
</li>
<li><a class="reference" href="#rounding" id="id28" name="id28">5.3&nbsp;&nbsp;&nbsp;Rounding</a></li>
<li><a class="reference" href="#exponent-range" id="id29" name="id29">5.4&nbsp;&nbsp;&nbsp;Exponent range</a></li>
<li><a class="reference" href="#compatibility" id="id30" name="id30">5.5&nbsp;&nbsp;&nbsp;Compatibility</a></li>
</ul>
</li>
<li><a class="reference" href="#performance-notes" id="id31" name="id31">6&nbsp;&nbsp;&nbsp;Performance notes</a><ul class="auto-toc">
<li><a class="reference" href="#optimization-tricks" id="id32" name="id32">6.1&nbsp;&nbsp;&nbsp;Optimization tricks</a></li>
<li><a class="reference" href="#using-the-right-tool" id="id33" name="id33">6.2&nbsp;&nbsp;&nbsp;Using the right tool</a></li>
</ul>
</li>
</ul>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id1" id="about-mpmath" name="about-mpmath">1&nbsp;&nbsp;&nbsp;About mpmath</a></h1>
<p>Mpmath is a pure-Python library for arbitrary-precision floating-point arithmetic. It implements all the functions found in Python's <tt class="docutils literal"><span class="pre">math</span></tt> and <tt class="docutils literal"><span class="pre">cmath</span></tt> modules (<tt class="docutils literal"><span class="pre">exp</span></tt>, <tt class="docutils literal"><span class="pre">log</span></tt>, <tt class="docutils literal"><span class="pre">sin</span></tt>...), plus a few nonelementary special functions (<tt class="docutils literal"><span class="pre">gamma</span></tt>, <tt class="docutils literal"><span class="pre">zeta</span></tt>...), and has utilities for arbitrary-precision numerical differentiation, integration, root-finding, and interval arithmetic. It supports unlimited exponents, has full support for complex numbers, and offers better performance than Python's standard <tt class="docutils literal"><span class="pre">decimal</span></tt> library.</p>
<p>Mpmath is lightweight (~100 KB), free (BSD license), and easy to install or include in other software due to being written entirely in Python without any external dependencies.</p>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id2" id="installation" name="installation">2&nbsp;&nbsp;&nbsp;Installation</a></h1>
<p>You can install the latest released version of mpmath by running:</p>
<pre class="literal-block">
python easy_install.py mpmath
</pre>
<p>or, on Windows:</p>
<pre class="literal-block">
C:\&lt;pythonpath&gt;\Scripts\easy_install.exe mpmath
</pre>
<p>Alternatively, you can manually download the latest released version of mpmath from the <a class="reference" href="http://code.google.com/p/mpmath/">mpmath website</a> or the <a class="reference" href="http://pypi.python.org/pypi">Python Package Index</a>. Either run the binary installer (Windows only) or extract the source archive and run:</p>
<pre class="literal-block">
python setup.py install
</pre>
<p>Debian and Ubuntu users can <tt class="docutils literal"><span class="pre">apt-get</span></tt> mpmath; <a class="reference" href="http://packages.debian.org/python-mpmath">package information</a> is available on the Debian website.</p>
<p>After the setup has completed, you should be able to fire up the interactive Python interpreter and do the following:</p>
<pre class="literal-block">
&gt;&gt;&gt; from mpmath import *
&gt;&gt;&gt; mp.dps = 50
&gt;&gt;&gt; print mpf(2) ** mpf('0.5')
1.4142135623730950488016887242096980785696718753769
&gt;&gt;&gt; print 2*pi
6.2831853071795864769252867665590057683943387987502
</pre>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id3" id="basic-arithmetic" name="basic-arithmetic">3&nbsp;&nbsp;&nbsp;Basic arithmetic</a></h1>
<div class="section">
<h2><a class="toc-backref" href="#id4" id="working-with-mpmath-numbers" name="working-with-mpmath-numbers">3.1&nbsp;&nbsp;&nbsp;Working with mpmath numbers</a></h2>
<p>Mpmath provides two main numerical types: <tt class="docutils literal"><span class="pre">mpf</span></tt> and <tt class="docutils literal"><span class="pre">mpc</span></tt>. The <tt class="docutils literal"><span class="pre">mpf</span></tt> type is analogous to Python's built-in <tt class="docutils literal"><span class="pre">float</span></tt>. It holds a real number or one of the special values <tt class="docutils literal"><span class="pre">inf</span></tt> (positive infinity), <tt class="docutils literal"><span class="pre">-inf</span></tt> and <tt class="docutils literal"><span class="pre">nan</span></tt> (not-a-number, indicating an indeterminate result). You can create <tt class="docutils literal"><span class="pre">mpf</span></tt> instances from strings, integers, floats, and other <tt class="docutils literal"><span class="pre">mpf</span></tt> instances:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mpf(4)
mpf('4.0')
&gt;&gt;&gt; mpf(2.5)
mpf('2.5')
&gt;&gt;&gt; mpf(&quot;1.25e6&quot;)
mpf('1250000.0')
&gt;&gt;&gt; mpf(mpf(2))
mpf('2.0')
&gt;&gt;&gt; mpf(&quot;inf&quot;)
mpf('+inf')
</pre>
</blockquote>
<p>An <tt class="docutils literal"><span class="pre">mpc</span></tt> represents a complex number in rectangular form as a pair of <tt class="docutils literal"><span class="pre">mpf</span></tt> instances. It can be constructed from a Python <tt class="docutils literal"><span class="pre">complex</span></tt>, a real number, or a pair of real numbers:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mpc(2,3)
mpc(real='2.0', imag='3.0')
&gt;&gt;&gt; mpc(complex(2,3)).imag
mpf('3.0')
</pre>
</blockquote>
<p>You can mix <tt class="docutils literal"><span class="pre">mpf</span></tt> and <tt class="docutils literal"><span class="pre">mpc</span></tt> instances with each other and with Python numbers:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mpf(3) + 2*mpf('2.5') + 1.0
mpf('9')
&gt;&gt;&gt; mpc(1j)**0.5
mpc(real='0.70710678118654757', imag='0.70710678118654757')
</pre>
</blockquote>
<p>Prettier output can be obtained by using <tt class="docutils literal"><span class="pre">str()</span></tt> or <tt class="docutils literal"><span class="pre">print</span></tt>, which hide the <tt class="docutils literal"><span class="pre">mpf</span></tt> and <tt class="docutils literal"><span class="pre">mpc</span></tt> constructor signatures and suppress small rounding artifacts:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mpf(&quot;3.14159&quot;)
mpf('3.1415899999999999')
&gt;&gt;&gt; print mpf(&quot;3.14159&quot;)
3.14159
&gt;&gt;&gt; print mpc(1j)**0.5
(0.707106781186548 + 0.707106781186548j)
</pre>
</blockquote>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id5" id="controlling-precision" name="controlling-precision">3.2&nbsp;&nbsp;&nbsp;Controlling precision</a></h2>
<p>Mpmath uses a global working precision; it does not keep track of the precision or accuracy of individual numbers. Performing an arithmetic operation or calling <tt class="docutils literal"><span class="pre">mpf()</span></tt> rounds the result to the current working precision. The working precision is controlled by a special object called <tt class="docutils literal"><span class="pre">mp</span></tt>, which has the following default state:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mp
Mpmath settings:
  mp.prec = 53                [default: 53]
  mp.dps = 15                 [default: 15]
  mp.rounding = 'nearest'     [default: 'nearest']
</pre>
</blockquote>
<p>The term <em>precision</em> (<strong>prec</strong>) always refers to the arithmetic precision measured in bits. The <em>decimal precision</em> is called the <strong>dps</strong> (short for <em>decimal places</em>). Binary and decimal precision are related roughly according to the formula <tt class="docutils literal"><span class="pre">prec</span> <span class="pre">=</span> <span class="pre">3.33*dps</span></tt>. For example, it takes a precision of roughly 333 bits to hold an approximation of pi that is accurate to 100 decimal places (actually slightly more than 333 bits is used; see the section &quot;Decimal issues&quot; below).</p>
<p>Changing one property of the <tt class="docutils literal"><span class="pre">mp</span></tt> object automatically updates the other; usually you just want to change the <tt class="docutils literal"><span class="pre">dps</span></tt> value:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mp.dps = 100
&gt;&gt;&gt; mp.dps
100
&gt;&gt;&gt; mp.prec
336
</pre>
</blockquote>
<p>When you've set the precision level, all <tt class="docutils literal"><span class="pre">mpf</span></tt> operations are carried out at that precision:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mp.dps = 50
&gt;&gt;&gt; mpf(1) / 6
mpf('0.16666666666666666666666666666666666666666666666666656')
&gt;&gt;&gt; mp.dps = 25
&gt;&gt;&gt; mpf(2) ** mpf('0.5')
mpf('1.414213562373095048801688713')
</pre>
</blockquote>
<p>The precision of complex arithmetic is also controlled by the <tt class="docutils literal"><span class="pre">mp</span></tt> object:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mp.dps = 10
&gt;&gt;&gt; mpc(1,2) / 3
mpc(real='0.3333333333321', imag='0.6666666666642')
</pre>
</blockquote>
<p>The number of digits with which numbers are printed by default is determined by the working precision. To specify the number of digits to show without changing the working precision, use the <tt class="docutils literal"><span class="pre">nstr</span></tt> and <tt class="docutils literal"><span class="pre">nprint</span></tt> functions:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mp.dps = 15
&gt;&gt;&gt; a = mpf(1) / 6
&gt;&gt;&gt; a
mpf('0.16666666666666666')
&gt;&gt;&gt; nstr(a, 8)
'0.16666667'
&gt;&gt;&gt; nprint(a, 8)
0.16666667
&gt;&gt;&gt; nstr(a, 50)
'0.16666666666666665741480812812369549646973609924316'
</pre>
</blockquote>
<div class="section">
<h3><a class="toc-backref" href="#id6" id="temporarily-changing-the-precision" name="temporarily-changing-the-precision">3.2.1&nbsp;&nbsp;&nbsp;Temporarily changing the precision</a></h3>
<p>It is often useful to change the precision during only part of a calculation. A way to temporarily increase the precision and then restore it is as follows:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mp.prec += 2
 (...)
&gt;&gt;&gt; mp.prec -= 2
</pre>
</blockquote>
<p>In Python 2.5, the <tt class="docutils literal"><span class="pre">with</span></tt> statement along with the mpmath functions <tt class="docutils literal"><span class="pre">workprec</span></tt>, <tt class="docutils literal"><span class="pre">workdps</span></tt>, <tt class="docutils literal"><span class="pre">extraprec</span></tt> and <tt class="docutils literal"><span class="pre">extradps</span></tt> can be used to temporarily change precision in a more safe manner:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; from __future__ import with_statement
&gt;&gt;&gt; with workdps(20):
...     print mpf(1)/7
...     with extradps(10):
...         print mpf(1)/7
...
0.14285714285714285714
0.142857142857142857142857142857
&gt;&gt;&gt; mp.dps
15
</pre>
</blockquote>
<p>The <tt class="docutils literal"><span class="pre">with</span></tt> statement ensures that the precision gets reset when exiting the block, even in the case that an exception is raised. (The effect of the <tt class="docutils literal"><span class="pre">with</span></tt> statement can be emulated in Python 2.4 by using a <tt class="docutils literal"><span class="pre">try/finally</span></tt> block.)</p>
<p>The <tt class="docutils literal"><span class="pre">workprec</span></tt> family of functions can also be used as function decorators:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; &#64;workdps(6)
... def f():
...     return mpf(1)/3
...
&gt;&gt;&gt; f()
mpf('0.33333331346511841')
</pre>
</blockquote>
</div>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id7" id="caveat-providing-correct-input" name="caveat-providing-correct-input">3.3&nbsp;&nbsp;&nbsp;Caveat: providing correct input</a></h2>
<p>Note that when creating a new <tt class="docutils literal"><span class="pre">mpf</span></tt>, the value will at most be as accurate as the input. <strong>Be careful when mixing mpmath numbers with Python floats</strong>. When working at high precision, fractional <tt class="docutils literal"><span class="pre">mpf</span></tt> values should be created from strings or integers:</p>
<pre class="doctest-block">
&gt;&gt;&gt; mp.dps = 30
&gt;&gt;&gt; mpf(10.9)   # bad
mpf('10.9000000000000003552713678800501')
&gt;&gt;&gt; mpf('10.9')  # good
mpf('10.9')
&gt;&gt;&gt; mpf(109) / mpf(10)   # also good
mpf('10.9')
</pre>
<p>(Binary fractions such as 0.5, 1.5, 0.75, 0.125, etc, are generally safe, however, since those can be represented exactly by Python floats.)</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id8" id="magical-numbers" name="magical-numbers">3.4&nbsp;&nbsp;&nbsp;Magical numbers</a></h2>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id9" id="mathematical-functions" name="mathematical-functions">3.5&nbsp;&nbsp;&nbsp;Mathematical functions</a></h2>
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id10" id="high-level-features" name="high-level-features">4&nbsp;&nbsp;&nbsp;High-level features</a></h1>
<div class="section">
<h2><a class="toc-backref" href="#id11" id="numerical-integration" name="numerical-integration">4.1&nbsp;&nbsp;&nbsp;Numerical integration</a></h2>
<p>The function <tt class="docutils literal"><span class="pre">quadts</span></tt> performs tanh-sinh quadrature (also known as doubly exponential quadrature). The syntax for integrating a function <em>f</em> between the endpoints <em>a</em> and <em>b</em> is <tt class="docutils literal"><span class="pre">quadts(f,</span> <span class="pre">a,</span> <span class="pre">b)</span></tt>. For example,</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; print quadts(sin, 0, pi)
2.0
</pre>
</blockquote>
<p>Tanh-sinh quadrature is extremely efficient for high-precision integration of analytic functions. Unlike the more well-known Gaussian quadrature algorithm, it is relatively insensitive to integrable singularities at the endpoints of the interval. The <tt class="docutils literal"><span class="pre">quadts</span></tt> function attempts to evaluate the integral to the full working precision; for example, it can calculate 100 digits of pi by integrating the area under the half circle arc <tt class="docutils literal"><span class="pre">x^2</span> <span class="pre">+</span> <span class="pre">y^2</span> <span class="pre">=</span> <span class="pre">1</span> <span class="pre">(y</span> <span class="pre">&gt;</span> <span class="pre">0)</span></tt>:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mp.dps = 100
&gt;&gt;&gt; print quadts(lambda x: 2*sqrt(1 - x**2), -1, 1)
3.14159265358979323846264338327950288419716939937510582097
4944592307816406286208998628034825342117068
</pre>
</blockquote>
<p>The tanh-sinh scheme is efficient enough that analytic 100-digit integrals like this one can often be evaluated in less than a second. The timings for computing this integral at various precision levels on the author's computer is:</p>
<table border="1" class="docutils">
<colgroup>
<col width="12%" />
<col width="43%" />
<col width="45%" />
</colgroup>
<tbody valign="top">
<tr><td>dps</td>
<td>First evaluation</td>
<td>Second evaluation</td>
</tr>
<tr><td>15</td>
<td>0.029 seconds</td>
<td>0.0060 seconds</td>
</tr>
<tr><td>50</td>
<td>0.15 seconds</td>
<td>0.016 seconds</td>
</tr>
<tr><td>500</td>
<td>16.3 seconds</td>
<td>0.50 seconds</td>
</tr>
</tbody>
</table>
<p>The second integration at the same precision level is much faster. The reason for this is that the tanh-sinh algorithm must be initalized by computing a set of nodes, and this initalization if often more expensive than actually evaluating the integral. Mpmath automatically caches all computed nodes to make subsequent integrations faster, but the cache is lost when Python shuts down, so if you would frequently like to use mpmath to calculate 1000-digit integrals, you may want to save the nodes to a file. The nodes are stored in a dict <tt class="docutils literal"><span class="pre">TS_cache</span></tt> located in the <tt class="docutils literal"><span class="pre">mpmath.calculus</span></tt> module, which can be pickled if desired.</p>
<div class="section">
<h3><a class="toc-backref" href="#id12" id="features-and-application-examples" name="features-and-application-examples">4.1.1&nbsp;&nbsp;&nbsp;Features and application examples</a></h3>
<p>You can integrate over infinite or half-infinite intervals:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; print quadts(lambda x: 2/(x**2+1), 0, inf)
3.14159265358979
&gt;&gt;&gt; print quadts(lambda x: exp(-x**2), -inf, inf)**2
3.14159265358979
</pre>
</blockquote>
<p>Complex integrals are also supported. The next example computes Euler's constant gamma by using Cauchy's integral formula and looking at the pole of the Riemann zeta function at <em>z</em> = 1.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; print 1/(2*pi) * quadts(lambda x: zeta(exp(j*x)+1), 0, 2*pi)
(0.577215664901533 + 2.86444093843177e-25j)
</pre>
</blockquote>
<p>Functions with integral representations, such as the gamma function, can be implemented  directly from the definition.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; def Gamma(z):
...     return quadts(lambda t: exp(-t)*t**(z-1), 0, inf)
...
&gt;&gt;&gt; print Gamma(1)
1.0
&gt;&gt;&gt; print Gamma(10)
362880.0
&gt;&gt;&gt; print Gamma(1+1j)
(0.498015668118356 - 0.154949828301811j)
</pre>
</blockquote>
</div>
<div class="section">
<h3><a class="toc-backref" href="#id13" id="double-integrals" name="double-integrals">4.1.2&nbsp;&nbsp;&nbsp;Double integrals</a></h3>
<p>It is possible to calculate double integrals with <tt class="docutils literal"><span class="pre">quadts</span></tt>. To do this, simply provide a two-argument function and, instead of two endpoints, provide two intervals. The first interval specifies the range for the <em>x</em> variable and the second interval specifies the range of the <em>y</em> variable.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; print quadts(lambda x, y: cos(x+y/2), (-pi/2, pi/2), (0, pi))
4.0
</pre>
</blockquote>
<p>Here are some more difficult examples taken from <a class="reference" href="http://mathworld.wolfram.com/DoubleIntegral.html">http://mathworld.wolfram.com/DoubleIntegral.html</a> (all except the second contain corner singularities). Each integral is calculated with <tt class="docutils literal"><span class="pre">mp.dps</span> <span class="pre">=</span> <span class="pre">30</span></tt> (which takes a couple of seconds), and the result is compared to the known analytical value.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; print quadts(lambda x, y: (x-1)/((1-x*y)*log(x*y)), (0, 1), (0, 1))
0.577215664901532860606512090082
&gt;&gt;&gt; print euler
0.577215664901532860606512090082
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; print quadts(lambda x, y: 1/sqrt(1+x**2+y**2), (-1, 1), (-1, 1))
3.17343648530607134219175646705
&gt;&gt;&gt; print 4*log(2+sqrt(3))-2*pi/3
3.17343648530607134219175646705
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; print quadts(lambda x, y: 1/(1-x**2 * y**2), (0, 1), (0, 1))
1.23370055013616982735431137498
&gt;&gt;&gt; print pi**2 / 8
1.23370055013616982735431137498
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; print quadts(lambda x, y: 1/(1-x*y), (0, 1), (0, 1))
1.64493406684822643647241516665
&gt;&gt;&gt; print pi**2 / 6
1.64493406684822643647241516665
</pre>
</blockquote>
<p>There is no direct support for computing triple or higher dimensional integrals; if desired, this can be done easily by passing a function that calls <cite>quadts()</cite> recursively. While double integrals are reasonably fast, even a simple triple integral at very low precision will probably take several minutes to calculate. A quadruple integral will require a whole lot of patience.</p>
</div>
<div class="section">
<h3><a class="toc-backref" href="#id14" id="error-detection" name="error-detection">4.1.3&nbsp;&nbsp;&nbsp;Error detection</a></h3>
<p>The tanh-sinh algorithm is not suitable for adaptive quadrature, and does not perform well if there are singularities between the endpoints or if the integrand is very bumpy or oscillatory (such integrals should manually be split into smaller pieces). If the <tt class="docutils literal"><span class="pre">error=1</span></tt> option is set, <tt class="docutils literal"><span class="pre">quadts</span></tt> will return an error estimate along with the result; although this estimate is not always correct, it can be useful for debugging.</p>
<p>A simple example where the algorithm fails is the function f(<em>x</em>) = abs(sin(<em>x</em>)), which is not smooth at <em>x</em> = pi. In this case, a close value is calculated, but the result is nowhere near the target accuracy; however, <tt class="docutils literal"><span class="pre">quadts</span></tt> gives a good estimate of the magnitude of the error:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mp.dps = 15
&gt;&gt;&gt; quadts(lambda x: abs(sin(x)), 0, 2*pi, error=1)
(mpf('3.9990089417677899'), mpf('0.001'))
</pre>
</blockquote>
<p>Attempting to evaluate oscillatory integrals on large intervals by means of the tanh-sinh method is generally futile. This integral should be pi/2 = 1.57:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; print quadts(lambda x: sin(x)/x, 0, inf, error=1)
(mpf('2.3840907358976544'), mpf('1.0'))
</pre>
</blockquote>
<p>The next integral should be approximately 0.627 but <cite>quadts</cite> generates complete nonsense both in the result and the error estimate (the error estimate is somewhat arbitrarily capped at 1.0):</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; print quadts(lambda x: sin(x**2), 0, inf, error=1)
(mpf('2.5190134849122411e+21'), mpf('1.0'))
</pre>
</blockquote>
<p>However, oscillation may not be a problem if suppressed by sufficiently fast decay. This integral is exactly 1/2.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; print quadts(lambda x: exp(-x)*sin(x), 0, inf)
0.5
</pre>
</blockquote>
<p>Even for analytic integrals on finite intervals, there is no guarantee that <cite>quadts</cite> will be successful. A few examples of integrals for which <cite>quadts</cite> currently fails to reach full accuracy are:</p>
<pre class="literal-block">
quadts(lambda x: sqrt(tan(x)), 0, pi/2)
quadts(lambda x: atan(x)/(x*sqrt(1-x**2)), 0, 1)
quadts(lambda x: log(1+x**2)/x**2, 0, 1)
quadts(lambda x: x**2/((1+x**4)*sqrt(1-x**4)), 0, 1)
</pre>
<p>Apparently simple-looking double integrals might not be possible to evaluate directly. In this example, <cite>quadts</cite> will run for several seconds before returning a value with very low accuracy:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mpf.dps = 15
&gt;&gt;&gt; quadts(lambda x, y: sqrt((x-0.5)**2+(y-0.5)**2), (0, 1), (0, 1), error=1)
(mpf('0.38259743528830826'), mpf('1.0e-6'))
</pre>
</blockquote>
<p>The problem is due to the non-analytic behavior of the function at (0.5, 0.5). We can do much better by splitting the area into four pieces (because of the symmetry, we only need to evaluate one of them):</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; print quadts(lambda x, y: 4*sqrt((x-0.5)**2+(y-0.5)**2), (0.5, 1), (0.5, 1))
0.382597858232106
&gt;&gt;&gt; print (sqrt(2) + asinh(1))/6
0.382597858232106
</pre>
</blockquote>
<p>The value agrees with the analytic result and the running time in this case is just 0.7 seconds.</p>
</div>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id15" id="numerical-differentiation" name="numerical-differentiation">4.2&nbsp;&nbsp;&nbsp;Numerical differentiation</a></h2>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id16" id="root-finding-with-the-secant-method" name="root-finding-with-the-secant-method">4.3&nbsp;&nbsp;&nbsp;Root-finding with the secant method</a></h2>
<p>The function <tt class="docutils literal"><span class="pre">secant</span></tt> calculates a root of a given function using the secant method. A good initial guess for the location of the root is required for the method to be effective, so it is somewhat more appropriate to think of the secant method as a root-polishing method than a root-finding method.</p>
<p>If the rough location of the root is known, the secant method can be used to refine it to very high precision in only a few steps. If the root is a first-order root, only roughly log(prec) iterations are required. (The secant method is far less efficient for double roots.) A particularly efficient general approach is to compute the initial approximation using a machine precision solver (for example using one of SciPy's many solvers), and then refining it to high precision using mpmath's <tt class="docutils literal"><span class="pre">secant</span></tt> method.</p>
<div class="section">
<h3><a class="toc-backref" href="#id17" id="simple-examples" name="simple-examples">4.3.1&nbsp;&nbsp;&nbsp;Simple examples</a></h3>
<p>A simple example use of the secant method is to compute pi as the root of sin(<em>x</em>) closest to <em>x</em> = 3.</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mp.dps = 30
&gt;&gt;&gt; print secant(sin, 3)
3.14159265358979323846264338328
</pre>
</blockquote>
<p>The secant method can be used to find complex roots of analytic functions, although it must in that case generally be given a nonreal starting value (or else it will never leave the real line).</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mp.dps = 15
&gt;&gt;&gt; print secant(lambda x: x**3 + 2*x + 1, j)
(0.226698825758202 + 1.46771150871022j)
</pre>
</blockquote>
</div>
<div class="section">
<h3><a class="toc-backref" href="#id18" id="applications" name="applications">4.3.2&nbsp;&nbsp;&nbsp;Applications</a></h3>
<p>A nice application is to compute nontrivial roots of the Riemann zeta function with many digits (good initial values are needed for convergence):</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mp.dps = 30
&gt;&gt;&gt; print secant(zeta, 0.5+14j)
(0.5 + 14.1347251417346937904572519836j)
</pre>
</blockquote>
<p>The secant method can also be used as an optimization algorithm, by passing it a derivative of a function. The following example locates the positive minimum of the gamma function:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mp.dps = 20
&gt;&gt;&gt; print secant(lambda x: diff(gamma, x), 1)
1.4616321449683623413
</pre>
</blockquote>
<p>Finally, a useful application is to compute inverse functions, such as the Lambert W function which is the inverse of <em>w</em> exp(<em>w</em>), given the first term of the solution's asymptotic expansion as the initial value:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; def lambert(x):
...     return secant(lambda w: w*exp(w) - x, log(1+x))
...
&gt;&gt;&gt; mp.dps = 15
&gt;&gt;&gt; print lambert(1)
0.567143290409784
&gt;&gt;&gt; print lambert(1000)
5.2496028524016
</pre>
</blockquote>
</div>
<div class="section">
<h3><a class="toc-backref" href="#id19" id="options" name="options">4.3.3&nbsp;&nbsp;&nbsp;Options</a></h3>
<p>Strictly speaking, the secant method requires two initial values. By default, you only have to provide the first point <tt class="docutils literal"><span class="pre">x0</span></tt>; <tt class="docutils literal"><span class="pre">secant</span></tt> automatically sets the second point to <tt class="docutils literal"><span class="pre">x0</span> <span class="pre">+</span> <span class="pre">1/4</span></tt>. Manually providing also the second point can help in some cases if <tt class="docutils literal"><span class="pre">secant</span></tt> fails to converge.</p>
<p>By default, <tt class="docutils literal"><span class="pre">secant</span></tt> performs a maximum of 20 steps, which can be increased or decreased using the <tt class="docutils literal"><span class="pre">maxsteps</span></tt> keyword argument. You can pass <tt class="docutils literal"><span class="pre">secant</span></tt> the option <tt class="docutils literal"><span class="pre">verbose=True</span></tt> to show detailed progress.</p>
</div>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id20" id="polynomials" name="polynomials">4.4&nbsp;&nbsp;&nbsp;Polynomials</a></h2>
<div class="section">
<h3><a class="toc-backref" href="#id21" id="polynomial-evaluation" name="polynomial-evaluation">4.4.1&nbsp;&nbsp;&nbsp;Polynomial evaluation</a></h3>
<p>Polynomial functions can be evaluated using <tt class="docutils literal"><span class="pre">polyval</span></tt>, which takes as input a list of coefficients and the desired evaluation point. The following example evaluates <tt class="docutils literal"><span class="pre">2</span> <span class="pre">+</span> <span class="pre">5*x</span> <span class="pre">+</span> <span class="pre">x^3</span></tt> at <tt class="docutils literal"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">3.5</span></tt>:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mp.dps = 20
&gt;&gt;&gt; polyval([2, 5, 0, 1], mpf('3.5'))
mpf('62.375')
</pre>
</blockquote>
<p>With <tt class="docutils literal"><span class="pre">derivative=True</span></tt>, both the polynomial and its derivative are evaluated at the same point:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; polyval([2, 5, 0, 1], mpf('3.5'), derivative=True)
(mpf('62.375'), mpf('41.75'))
</pre>
</blockquote>
<p>The point and coefficient list may contain complex numbers.</p>
</div>
<div class="section">
<h3><a class="toc-backref" href="#id22" id="finding-roots-of-polynomials" name="finding-roots-of-polynomials">4.4.2&nbsp;&nbsp;&nbsp;Finding roots of polynomials</a></h3>
<p>The function <tt class="docutils literal"><span class="pre">polyroots</span></tt> computes all <em>n</em> real or complex roots of an <em>n</em>-th degree polynomial using complex arithmetic, and returns them along with an error estimate. As a simple example, it will successfully compute the two real roots <tt class="docutils literal"><span class="pre">3*x^2</span> <span class="pre">-</span> <span class="pre">7*x</span> <span class="pre">+</span> <span class="pre">2</span></tt> (which are 1/3 and 2):</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; roots, err = polyroots([2, -7, 3])
&gt;&gt;&gt; print err
2.66453525910038e-16
&gt;&gt;&gt; for root in roots:
...     print root
...
(0.333333333333333 - 9.62964972193618e-35j)
(2.0 + 1.5395124730131e-50j)
</pre>
</blockquote>
<p>As should be expected from the internal use of complex arithmetic, the calculated roots have small but nonzero imaginary parts.</p>
<p>The following example computes all the 5th roots of unity; i.e. the roots of <tt class="docutils literal"><span class="pre">x^5</span> <span class="pre">-</span> <span class="pre">1</span></tt>:</p>
<blockquote>
<pre class="doctest-block">
&gt;&gt;&gt; mp.dps = 20
&gt;&gt;&gt; for a in polyroots([-1, 0, 0, 0, 0, 1])[0]:
...     print a
...
(-0.8090169943749474241 + 0.58778525229247312917j)
(1.0 + 0.0j)
(0.3090169943749474241 + 0.95105651629515357212j)
(-0.8090169943749474241 - 0.58778525229247312917j)
(0.3090169943749474241 - 0.95105651629515357212j)
</pre>
</blockquote>
</div>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id23" id="interval-arithmetic" name="interval-arithmetic">4.5&nbsp;&nbsp;&nbsp;Interval arithmetic</a></h2>
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id24" id="technical-details" name="technical-details">5&nbsp;&nbsp;&nbsp;Technical details</a></h1>
<p>Doing a high-precision calculation in mpmath typically just amounts to setting the precision and entering a formula. However, some knowledge of mpmath's terminology and internal number model can be useful to avoid common errors, and is recommended for trying more advanced calculations.</p>
<div class="section">
<h2><a class="toc-backref" href="#id25" id="representation-of-numbers" name="representation-of-numbers">5.1&nbsp;&nbsp;&nbsp;Representation of numbers</a></h2>
<p>Mpmath uses binary arithmetic. A binary floating-point number is a number of the form <tt class="docutils literal"><span class="pre">man</span> <span class="pre">*</span> <span class="pre">2^exp</span></tt> where both <tt class="docutils literal"><span class="pre">man</span></tt> (the <em>mantissa</em>) and <tt class="docutils literal"><span class="pre">exp</span></tt> (the <em>exponent</em>) are integers. Some examples of floating-point numbers are given in the following table.</p>
<blockquote>
<table border="1" class="docutils">
<colgroup>
<col width="29%" />
<col width="36%" />
<col width="36%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Number</th>
<th class="head">Mantissa</th>
<th class="head">Exponent</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>3</td>
<td>3</td>
<td>0</td>
</tr>
<tr><td>10</td>
<td>5</td>
<td>1</td>
</tr>
<tr><td>-16</td>
<td>-1</td>
<td>4</td>
</tr>
<tr><td>1.25</td>
<td>5</td>
<td>-2</td>
</tr>
</tbody>
</table>
</blockquote>
<p>Note that the representation as defined so far is not unique; one can always multiply the mantissa by 2 and subtract 1 from the exponent with no change in the numerical value. In mpmath, numbers are always normalized so that <tt class="docutils literal"><span class="pre">man</span></tt> is an odd number, unless it is 0; we take zero to have <tt class="docutils literal"><span class="pre">man</span> <span class="pre">=</span> <span class="pre">exp</span> <span class="pre">=</span> <span class="pre">0</span></tt>. With these conventions, every representable number has a unique representation. (Mpmath does not currently distinguish between positive and negative zero.)</p>
<p>Simple mathematical operations are now easy to define. Due to uniqueness, equality testing of two numbers simply amounts to separately checking equality of the mantissas and the exponents. Multiplication of nonzero numbers is straightforward: <tt class="docutils literal"><span class="pre">(m*2^e)</span> <span class="pre">*</span> <span class="pre">(n*2^f)</span> <span class="pre">=</span> <span class="pre">(m*n)</span> <span class="pre">*</span> <span class="pre">2^(e+f)</span></tt>. Addition is a bit more involved: we first need to multiply the mantissa of one of the operands by a suitable power of 2 to obtain equal exponents.</p>
<p>More technically, mpmath represents a floating-point number as a 4-tuple <tt class="docutils literal"><span class="pre">(sign,</span> <span class="pre">man,</span> <span class="pre">exp,</span> <span class="pre">bc)</span></tt> where <cite>sign</cite> is 0 or 1 (indicating positive vs negative) and the mantissa is nonnegative; <tt class="docutils literal"><span class="pre">bc</span></tt> (<em>bitcount</em>) is the size of the absolute value of the mantissa as measured in bits. Though redundant, keeping a separate sign field and explicitly keeping track of the bitcount significantly speeds up arithmetic (the bitcount, especially, is frequently needed but slow to compute from scratch due to the lack of a Python built-in function for the purpose).</p>
<p>The special numbers <tt class="docutils literal"><span class="pre">+inf</span></tt>, <tt class="docutils literal"><span class="pre">-inf</span></tt> and <tt class="docutils literal"><span class="pre">nan</span></tt> are represented internally by a zero mantissa and a nonzero exponent.</p>
<p>For further details on how the arithmetic is implemented, refer to the mpmath source code. The basic arithmetic operations are found in the <tt class="docutils literal"><span class="pre">lib.py</span></tt> module; many functions there are commented extensively.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id26" id="precision-and-accuracy" name="precision-and-accuracy">5.2&nbsp;&nbsp;&nbsp;Precision and accuracy</a></h2>
<p>Contrary to popular superstition, floating-point numbers  do not come with an inherent &quot;small uncertainty&quot;. Every binary floating-point number is an exact rational number. With arbitrary-precision integers used for the mantissa and exponent, floating-point numbers can be added, subtracted and multiplied <em>exactly</em>. In particular, integers and integer multiples of 1/2, 1/4, 1/8, 1/16, etc. can be represented, added and multiplied exactly in binary floating-point.</p>
<p>The reason why floating-point arithmetic is generally approximate is that we set a limit to the size of the mantissa for efficiency reasons. The maximum allowed width (bitcount) of the mantissa is called the precision or <tt class="docutils literal"><span class="pre">prec</span></tt> for short. Sums and products are exact as long as the absolute value of the mantissa is smaller than <tt class="docutils literal"><span class="pre">2^prec</span></tt>. As soon as the mantissa becomes larger than this threshold, we truncate it to have at most  <tt class="docutils literal"><span class="pre">prec</span></tt> bits (the exponent is incremented accordingly to preserve the magnitude of the number), and it is this operation that typically introduces numerical errors. Division is also not generally exact; although we can add and multiply exactly by setting the precision high enough, no precision is high enough to represent for example 1/3 exactly (the same obviously applies for roots, trigonometric functions, etc).</p>
<div class="section">
<h3><a class="toc-backref" href="#id27" id="decimal-issues" name="decimal-issues">5.2.1&nbsp;&nbsp;&nbsp;Decimal issues</a></h3>
<p>Unfortunately for some applications, decimal fractions fall into the category of numbers that generally cannot be represented exactly in binary floating-point form. For example, none of the numbers <tt class="docutils literal"><span class="pre">0.1</span></tt>, <tt class="docutils literal"><span class="pre">0.01</span></tt>, <tt class="docutils literal"><span class="pre">0.001</span></tt> has an exact representation as a binary floating-point number. Mpmath does not fully solve this problem; users who need <em>exact</em> decimal fractions should look at the <tt class="docutils literal"><span class="pre">decimal</span></tt> module in Python's standard library.</p>
<p>There are a few subtle differences between binary and decimal precision. Precision and accuracy do not always correlate when translating from binary to decimal. As a simple example, the number 0.1 has a decimal precision of 1 digit but is an infinitely accurate representation of 1/10. Conversely, the number 2^-50 has a binary representation with 1 bit of precision that is infinitely accurate; the same number can actually be represented exactly as a decimal, but doing so requires 35 significant digits:</p>
<blockquote>
0.00000000000000088817841970012523233890533447265625</blockquote>
<p>Generally, it works out to just choose 1000 * 3.33 bits of precision in order to obtain 1000 decimal digits. In fact, mpmath will do the conversion automatically for you: you can enter a desired <em>dps</em> value and mpmath will automatically choose the appropriate <em>prec</em>. More precisely, mpmath uses the following formulas to translate between prec and dps:</p>
<pre class="literal-block">
dps(prec) = max(1, int(round(int(prec) / C - 1)))

prec(dps) = max(1, int(round((int(dps) + 1) * C)))
</pre>
<p>where <tt class="docutils literal"><span class="pre">C</span> <span class="pre">=</span> <span class="pre">log(10)/log(2)</span></tt> is the exact version of the &quot;3.33&quot; conversion ratio. Note that the dps is set 1 decimal digit lower than the corresponding binary precision. This margin is added to ensure that <em>n</em>-digit decimal numbers, when converted to binary, will retain all <em>n</em> digits correct when converted back to decimal.</p>
<blockquote>
<ul class="simple">
<li>The <tt class="docutils literal"><span class="pre">str</span></tt> decimal precision is roughly one digit less than the exact equivalent binary precision, to hide minor rounding errors and artifacts resulting from binary-decimal conversion</li>
<li>The <tt class="docutils literal"><span class="pre">repr</span></tt> decimal precision is roughly one digit greater to ensure that <tt class="docutils literal"><span class="pre">x</span> <span class="pre">==</span> <span class="pre">eval(repr(x))</span></tt> holds, i.e. that numbers can be converted to strings and back losslessly.</li>
</ul>
</blockquote>
<p>For example, the standard precision is 53 bits, which corresponds to a dps value of 15. The actual decimal precision given by 53 bits is 15.95 ~= 16.</p>
<p>The dps value controls the number of digits to display when printing numbers with <tt class="docutils literal"><span class="pre">str</span></tt>, while the decimal precision used by <tt class="docutils literal"><span class="pre">repr</span></tt> is set two or three digits higher. For example, with 15 dps we have:</p>
<pre class="literal-block">
&gt;&gt;&gt; str(pi)
'3.14159265358979'
&gt;&gt;&gt; repr(+pi)
&quot;mpf('3.1415926535897931')&quot;
</pre>
</div>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id28" id="rounding" name="rounding">5.3&nbsp;&nbsp;&nbsp;Rounding</a></h2>
<p>There are several different strategies for rounding a too large mantissa or a result that cannot at all be represented exactly in floating-point form (such as <tt class="docutils literal"><span class="pre">log(2)</span></tt>). Mpmath supports the following rounding modes:</p>
<blockquote>
<table border="1" class="docutils">
<colgroup>
<col width="16%" />
<col width="84%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Name</th>
<th class="head">Direction</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>Floor</td>
<td>Towards negative infinity</td>
</tr>
<tr><td>Ceiling</td>
<td>Towards positive infinity</td>
</tr>
<tr><td>Down</td>
<td>Towards 0</td>
</tr>
<tr><td>Up</td>
<td>Away from 0</td>
</tr>
<tr><td>Nearest</td>
<td>To nearest; to the nearest even number on a tie</td>
</tr>
</tbody>
</table>
</blockquote>
<p>The first four modes are called <em>directed</em> rounding schemes and are useful for implementing interval arithmetic; they are also fast. Rounding to nearest, which mpmath uses by default, is the slowest but most accurate method.</p>
<p>The arithmetic operations <tt class="docutils literal"><span class="pre">+</span></tt>, <tt class="docutils literal"><span class="pre">-</span></tt>, <tt class="docutils literal"><span class="pre">*</span></tt> and <tt class="docutils literal"><span class="pre">/</span></tt> acting on real floating-point numbers always round their results <em>correctly</em> in mpmath; that is, they are guaranteed to give exact results when possible, they always round in the intended direction, and they don't round to a number farther away than necessary. Exponentiation by an integer <em>n</em> preserves directions but may round too far if either the mantissa or <em>n</em> is very large.</p>
<p>Evaluation of transcendental functions (as well as square roots) is generally performed by computing an approximation with finite precision slightly higher than the target precision, and rounding the result. This gives correctly rounded results with a high probability, but can be wrong in exceptional cases.</p>
<p>Rounding for radix conversion is a slightly tricky business. When converting to a binary floating-point number from a decimal string, mpmath writes the number as an exact fraction and performs correct rounding division if the number is of reasonable size (roughly, larger than 10^-100 and smaller than 10^100). When converting from binary to decimal, mpmath first performs an approximate radix conversion with slightly increased precision, then truncates the resulting decimal number to remove long sequences of trailing 0's and 9's, and finally rounds to nearest, rounding up (away from zero) on a tie.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id29" id="exponent-range" name="exponent-range">5.4&nbsp;&nbsp;&nbsp;Exponent range</a></h2>
<p>In hardware floating-point arithmetic, the size of the exponent is restricted to a fixed range: regular Python floats have a range between roughly 10^-300 and 10^300. Mpmath uses arbitrary precision integers for both the mantissa and the exponent, so numbers can be as large in magnitude as permitted by computer's memory. Mpmath can for example hold an approximation of a large Mersenne prime:</p>
<pre class="literal-block">
&gt;&gt;&gt; print mpf(2)**32582657 - 1
1.24575026015369e+9808357
</pre>
<p>Or why not 1 googolplex:</p>
<pre class="literal-block">
&gt;&gt;&gt; print mpf(10) ** (10**100)
1.0e+100000000000000000000000000000000000000000000000000
00000000000000000000000000000000000000000000000000
</pre>
<p>Some care may be necessary when working with extremely large numbers. Although arithmetic is safe, it is for example futile to attempt to compute <tt class="docutils literal"><span class="pre">exp</span></tt> of either of the above two numbers. Mpmath does not complain when asked to perform such a calculation, but instead chugs away on the problem to the best of its ability, assuming that computer resources are infinite. In the worst case, this will be slow and allocate a huge amount of memory; if entirely impossible Python will at some point raise <tt class="docutils literal"><span class="pre">OverflowError:</span> <span class="pre">long</span> <span class="pre">int</span> <span class="pre">too</span> <span class="pre">large</span> <span class="pre">to</span> <span class="pre">convert</span> <span class="pre">to</span> <span class="pre">int</span></tt>.</p>
<p>In some situations, it would be more convenient if mpmath would &quot;round&quot; extremely small numbers to 0 and extremely large numbers to <tt class="docutils literal"><span class="pre">inf</span></tt>, and directly raise an exception or return <tt class="docutils literal"><span class="pre">nan</span></tt> if there is no reasonable chance of finishing a computation. This option is not available, but could be implemented in the future on demand.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id30" id="compatibility" name="compatibility">5.5&nbsp;&nbsp;&nbsp;Compatibility</a></h2>
<p>The floating-point arithmetic provided by processors that conform to the IEEE 754 <em>double precision</em> standard has a precision of 53 bits and rounds to nearest. (Additional precision and rounding modes are usually available, but regular double precision arithmetic should be the most familiar to Python users, since the Python <tt class="docutils literal"><span class="pre">float</span></tt> type corresponds to an IEEE double with rounding to nearest on most systems.)</p>
<p>This corresponds roughly to a decimal accuracy of 15 digits, and is the default precision used by mpmath. Thus, under normal circumstances, mpmath should produce identical results to Python <tt class="docutils literal"><span class="pre">float</span></tt> operations. This is not always true, for the following reasons:</p>
<ol class="arabic simple">
<li>Hardware floats have a limited exponent range, as discussed above. Machine floats very close to the exponent limit may be rounded subnormally, meaning that they lose precision. Python may also raise an exception instead of rounding a <tt class="docutils literal"><span class="pre">float</span></tt> subnormally.</li>
<li>Hardware floating-point operations don't always round correctly. This is commonly the case for hardware implementations of transcendental functions like <tt class="docutils literal"><span class="pre">log</span></tt> and <tt class="docutils literal"><span class="pre">sin</span></tt>, but even square roots seem to be inaccurate on some systems, and mpmath has been run on at least one modern system where Python's builtin <tt class="docutils literal"><span class="pre">float</span></tt> multiplication was inaccurate, causing mpmath's float compatibility tests to fail.</li>
<li>Mpmath may of course have bugs. (However, the basic arithmetic has been tested fairly thoroughly by now. (1) and (2) are the more common causes of discrepancies.)</li>
</ol>
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id31" id="performance-notes" name="performance-notes">6&nbsp;&nbsp;&nbsp;Performance notes</a></h1>
<p>In rough numbers, Python floats are 100 times slower than raw hardware floats, and mpmath floats at standard precision are 100 times slower than Python floats. It's fortunate that a modern CPU does some 10^9 operations per second, at least leaving some 10^5 operations per second for mpmath (which is plenty for many uses). Because most time at low precision levels is spent on bookkeeping and interpreter overhead, the execution time increases sublinearly with small increments in precision. 50-digit arithmetic is essentially as fast as 15-digit arithmetic.  Asymptotically, mpmath arithmetic is as fast as Python big integer arithmetic, which is actually quite efficient up to several thousand digits (thanks to the use of Karatsuba multiplication).</p>
<div class="section">
<h2><a class="toc-backref" href="#id32" id="optimization-tricks" name="optimization-tricks">6.1&nbsp;&nbsp;&nbsp;Optimization tricks</a></h2>
<p>There are a few tricks that can significantly speed up mpmath code at low to medium precision (up to a few hundred digits):</p>
<blockquote>
<ul class="simple">
<li>Repeated type conversions from floats, strings and integers should be avoided.</li>
<li>Changing the rounding mode to <em>floor</em> can give a slight speedup.</li>
<li>The JIT compiler <a class="reference" href="http://psyco.sourceforge.net/">psyco</a> fairly consistently speeds up mpmath about 2x.</li>
<li>An additional 2x gain is possible by using the low-level functions in <tt class="docutils literal"><span class="pre">mpmath.lib</span></tt> instead of <tt class="docutils literal"><span class="pre">mpf</span></tt> instances.</li>
</ul>
</blockquote>
<p>Here follows a simple example demonstrating some of these options.</p>
<p>Original algorithm (0.028 seconds):</p>
<pre class="literal-block">
x = mpf(1)
for i in range(1000):
    x += 0.1
</pre>
<p>Preconverting the float constant (0.080 seconds):</p>
<pre class="literal-block">
x = mpf(1)
one_tenth = mpf(0.1)
for i in range(1000):
    x += one_tenth
</pre>
<p>With psyco (0.0036 seconds):</p>
<pre class="literal-block">
import psyco; psyco.full()
x = mpf(1)
one_tenth = mpf(0.1)
for i in range(1000):
    x += one_tenth
</pre>
<p>With psyco and low-level functions (0.0017 seconds):</p>
<pre class="literal-block">
import psyco; psyco.full()
x = from_int(1)
one_tenth = from_float(0.1)
for i in range(1000):
    x = fadd(x, one_tenth, 53, round_nearest)
</pre>
<p>The last version is 16.5 times faster than the first. Not all calculations can be sped up the same way, of course, or doing so may just be inconvenient.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id33" id="using-the-right-tool" name="using-the-right-tool">6.2&nbsp;&nbsp;&nbsp;Using the right tool</a></h2>
<p>Many calculations can be done with ordinary floating-point arithmetic, and only in special cases require multiprecision arithmetic (for example to avoid overflows in corner cases). In these situations, it may be possible to write code that uses fast regular floats by default, and automatically (or manually) falls backs to mpmath only when needed. Python's dynamic namespaces and ability to compile code on the fly are helpful. Here is a simple (probably not failsafe) example:</p>
<pre class="literal-block">
import math
import mpmath

def evalmath(expr):
    try:
        r = eval(expr, math.__dict__)
    except OverflowError:
        r = eval(expr, mpmath.__dict__)
        try:
            r = float(r)
        except OverflowError:
            pass
    return r

&gt;&gt;&gt; evalmath('sin(3)')
0.14112000805986721
&gt;&gt;&gt;
&gt;&gt;&gt; evalmath('exp(10000)')
mpf('8.8068182256629216e+4342')
&gt;&gt;&gt;
&gt;&gt;&gt; evalmath('exp(10000) / exp(10000)')
1.0
</pre>
</div>
</div>
</div>
</body>
</html>
