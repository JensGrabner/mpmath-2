<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Docutils 0.4: http://docutils.sourceforge.net/" />
<title>Mpmath manual</title>
<meta name="author" content="Fredrik Johansson" />
<style type="text/css">

/*
:Author: David Goodger
:Contact: goodger@users.sourceforge.net
:Date: $Date: 2005-12-18 01:56:14 +0100 (Sun, 18 Dec 2005) $
:Revision: $Revision: 4224 $
:Copyright: This stylesheet has been placed in the public domain.

Default cascading style sheet for the HTML output of Docutils.

See http://docutils.sf.net/docs/howto/html-stylesheets.html for how to
customize this style sheet.
*/

/* used to remove borders from tables and images */
.borderless, table.borderless td, table.borderless th {
  border: 0 }

table.borderless td, table.borderless th {
  /* Override padding for "table.docutils td" with "! important".
     The right padding separates the table cells. */
  padding: 0 0.5em 0 0 ! important }

.first {
  /* Override more specific margin styles with "! important". */
  margin-top: 0 ! important }

.last, .with-subtitle {
  margin-bottom: 0 ! important }

.hidden {
  display: none }

a.toc-backref {
  text-decoration: none ;
  color: black }

blockquote.epigraph {
  margin: 2em 5em ; }

dl.docutils dd {
  margin-bottom: 0.5em }

/* Uncomment (and remove this text!) to get bold-faced definition list terms
dl.docutils dt {
  font-weight: bold }
*/

div.abstract {
  margin: 2em 5em }

div.abstract p.topic-title {
  font-weight: bold ;
  text-align: center }

div.admonition, div.attention, div.caution, div.danger, div.error,
div.hint, div.important, div.note, div.tip, div.warning {
  margin: 2em ;
  border: medium outset ;
  padding: 1em }

div.admonition p.admonition-title, div.hint p.admonition-title,
div.important p.admonition-title, div.note p.admonition-title,
div.tip p.admonition-title {
  font-weight: bold ;
  font-family: sans-serif }

div.attention p.admonition-title, div.caution p.admonition-title,
div.danger p.admonition-title, div.error p.admonition-title,
div.warning p.admonition-title {
  color: red ;
  font-weight: bold ;
  font-family: sans-serif }

/* Uncomment (and remove this text!) to get reduced vertical space in
   compound paragraphs.
div.compound .compound-first, div.compound .compound-middle {
  margin-bottom: 0.5em }

div.compound .compound-last, div.compound .compound-middle {
  margin-top: 0.5em }
*/

div.dedication {
  margin: 2em 5em ;
  text-align: center ;
  font-style: italic }

div.dedication p.topic-title {
  font-weight: bold ;
  font-style: normal }

div.figure {
  margin-left: 2em ;
  margin-right: 2em }

div.footer, div.header {
  clear: both;
  font-size: smaller }

div.line-block {
  display: block ;
  margin-top: 1em ;
  margin-bottom: 1em }

div.line-block div.line-block {
  margin-top: 0 ;
  margin-bottom: 0 ;
  margin-left: 1.5em }

div.sidebar {
  margin-left: 1em ;
  border: medium outset ;
  padding: 1em ;
  background-color: #ffffee ;
  width: 40% ;
  float: right ;
  clear: right }

div.sidebar p.rubric {
  font-family: sans-serif ;
  font-size: medium }

div.system-messages {
  margin: 5em }

div.system-messages h1 {
  color: red }

div.system-message {
  border: medium outset ;
  padding: 1em }

div.system-message p.system-message-title {
  color: red ;
  font-weight: bold }

div.topic {
  margin: 2em }

h1.section-subtitle, h2.section-subtitle, h3.section-subtitle,
h4.section-subtitle, h5.section-subtitle, h6.section-subtitle {
  margin-top: 0.4em }

h1.title {
  text-align: center }

h2.subtitle {
  text-align: center }

hr.docutils {
  width: 75% }

img.align-left {
  clear: left }

img.align-right {
  clear: right }

ol.simple, ul.simple {
  margin-bottom: 1em }

ol.arabic {
  list-style: decimal }

ol.loweralpha {
  list-style: lower-alpha }

ol.upperalpha {
  list-style: upper-alpha }

ol.lowerroman {
  list-style: lower-roman }

ol.upperroman {
  list-style: upper-roman }

p.attribution {
  text-align: right ;
  margin-left: 50% }

p.caption {
  font-style: italic }

p.credits {
  font-style: italic ;
  font-size: smaller }

p.label {
  white-space: nowrap }

p.rubric {
  font-weight: bold ;
  font-size: larger ;
  color: maroon ;
  text-align: center }

p.sidebar-title {
  font-family: sans-serif ;
  font-weight: bold ;
  font-size: larger }

p.sidebar-subtitle {
  font-family: sans-serif ;
  font-weight: bold }

p.topic-title {
  font-weight: bold }

pre.address {
  margin-bottom: 0 ;
  margin-top: 0 ;
  font-family: serif ;
  font-size: 100% }

pre.literal-block, pre.doctest-block {
  margin-left: 2em ;
  margin-right: 2em ;
  background-color: #eeeeee }

span.classifier {
  font-family: sans-serif ;
  font-style: oblique }

span.classifier-delimiter {
  font-family: sans-serif ;
  font-weight: bold }

span.interpreted {
  font-family: sans-serif }

span.option {
  white-space: nowrap }

span.pre {
  white-space: pre }

span.problematic {
  color: red }

span.section-subtitle {
  /* font-size relative to parent (h1..h6 element) */
  font-size: 80% }

table.citation {
  border-left: solid 1px gray;
  margin-left: 1px }

table.docinfo {
  margin: 2em 4em }

table.docutils {
  margin-top: 0.5em ;
  margin-bottom: 0.5em }

table.footnote {
  border-left: solid 1px black;
  margin-left: 1px }

table.docutils td, table.docutils th,
table.docinfo td, table.docinfo th {
  padding-left: 0.5em ;
  padding-right: 0.5em ;
  vertical-align: top }

table.docutils th.field-name, table.docinfo th.docinfo-name {
  font-weight: bold ;
  text-align: left ;
  white-space: nowrap ;
  padding-left: 0 }

h1 tt.docutils, h2 tt.docutils, h3 tt.docutils,
h4 tt.docutils, h5 tt.docutils, h6 tt.docutils {
  font-size: 100% }

tt.docutils {
  background-color: #eeeeee }

ul.auto-toc {
  list-style-type: none }

body {
    margin:0px;
    padding:25px;
    background-color: #ccc;
    font-size: 13px; font-family: arial, sans-serif;
    line-height:1.5em;
}

div.document {
    max-width: 700px;
    color: #000;
    background-color: #fff;
    padding:25px;
    border:5px solid #ddd;
}

h1 {
    margin-top:0;
    padding-top:20px;
}

table {
    border-collapse: collapse;
}

pre, tt {
  font-family: consolas, lucida console, courier new, monospace;
}

pre.literal-block, pre.doctest-block {
  line-height:1.3em;
  border-top:1px solid #ccc;
  border-bottom:1px solid #ccc;
  background-color:#f0f0f0;
}


</style>
</head>
<body>
<div class="document" id="mpmath-manual">
<h1 class="title">Mpmath manual</h1>
<table class="docinfo" frame="void" rules="none">
<col class="docinfo-name" />
<col class="docinfo-content" />
<tbody valign="top">
<tr><th class="docinfo-name">Author:</th>
<td>Fredrik Johansson</td></tr>
<tr class="field"><th class="docinfo-name">E-mail:</th><td class="field-body"><a class="reference" href="mailto:fredrik.johansson&#64;gmail.com">fredrik.johansson&#64;gmail.com</a></td>
</tr>
<tr class="field"><th class="docinfo-name">Updated:</th><td class="field-body">2008-03-12</td>
</tr>
<tr class="field"><th class="docinfo-name">Mpmath version:</th><td class="field-body">0.7</td>
</tr>
</tbody>
</table>
<!-- -*- rest -*- -->
<div class="contents local topic">
<p class="topic-title first"><a id="table-of-contents" name="table-of-contents">Table of contents</a></p>
<ul class="auto-toc simple">
<li><a class="reference" href="#about-this-document" id="id1" name="id1">1&nbsp;&nbsp;&nbsp;About this document</a></li>
<li><a class="reference" href="#basics" id="id2" name="id2">2&nbsp;&nbsp;&nbsp;Basics</a><ul class="auto-toc">
<li><a class="reference" href="#mpmath-numbers" id="id3" name="id3">2.1&nbsp;&nbsp;&nbsp;Mpmath numbers</a></li>
<li><a class="reference" href="#setting-the-precision" id="id4" name="id4">2.2&nbsp;&nbsp;&nbsp;Setting the precision</a></li>
<li><a class="reference" href="#providing-correct-input" id="id5" name="id5">2.3&nbsp;&nbsp;&nbsp;Providing correct input</a></li>
<li><a class="reference" href="#special-numbers" id="id6" name="id6">2.4&nbsp;&nbsp;&nbsp;Special numbers</a></li>
<li><a class="reference" href="#mathematical-functions" id="id7" name="id7">2.5&nbsp;&nbsp;&nbsp;Mathematical functions</a></li>
</ul>
</li>
<li><a class="reference" href="#high-level-features" id="id8" name="id8">3&nbsp;&nbsp;&nbsp;High-level features</a><ul class="auto-toc">
<li><a class="reference" href="#integration" id="id9" name="id9">3.1&nbsp;&nbsp;&nbsp;Integration</a></li>
<li><a class="reference" href="#differentiation" id="id10" name="id10">3.2&nbsp;&nbsp;&nbsp;Differentiation</a></li>
<li><a class="reference" href="#root-finding" id="id11" name="id11">3.3&nbsp;&nbsp;&nbsp;Root-finding</a></li>
<li><a class="reference" href="#polynomials" id="id12" name="id12">3.4&nbsp;&nbsp;&nbsp;Polynomials</a></li>
<li><a class="reference" href="#interval-arithmetic" id="id13" name="id13">3.5&nbsp;&nbsp;&nbsp;Interval arithmetic</a></li>
</ul>
</li>
<li><a class="reference" href="#technical-details" id="id14" name="id14">4&nbsp;&nbsp;&nbsp;Technical details</a><ul class="auto-toc">
<li><a class="reference" href="#representation-of-numbers" id="id15" name="id15">4.1&nbsp;&nbsp;&nbsp;Representation of numbers</a></li>
<li><a class="reference" href="#precision-and-accuracy" id="id16" name="id16">4.2&nbsp;&nbsp;&nbsp;Precision and accuracy</a></li>
<li><a class="reference" href="#rounding" id="id17" name="id17">4.3&nbsp;&nbsp;&nbsp;Rounding</a></li>
<li><a class="reference" href="#exponent-range" id="id18" name="id18">4.4&nbsp;&nbsp;&nbsp;Exponent range</a></li>
<li><a class="reference" href="#compatibility" id="id19" name="id19">4.5&nbsp;&nbsp;&nbsp;Compatibility</a></li>
</ul>
</li>
<li><a class="reference" href="#optimization-tricks" id="id20" name="id20">5&nbsp;&nbsp;&nbsp;Optimization tricks</a></li>
</ul>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id1" id="about-this-document" name="about-this-document">1&nbsp;&nbsp;&nbsp;About this document</a></h1>
<p>This document is a guide to mpmath, a Python library for arbitrary-precision floating-point arithmetic. For general information about mpmath, see the website <a class="reference" href="http://code.google.com/p/mpmath/">http://code.google.com/p/mpmath/</a>. The most up-to-date version of this document is available at the mpmath website in the following formats:</p>
<ul class="simple">
<li><a class="reference" href="http://mpmath.googlecode.com/svn/trunk/doc/manual.html">http://mpmath.googlecode.com/svn/trunk/doc/manual.html</a> (HTML)</li>
<li><a class="reference" href="http://mpmath.googlecode.com/svn/trunk/doc/manual.pdf">http://mpmath.googlecode.com/svn/trunk/doc/manual.pdf</a> (PDF)</li>
</ul>
<p>This manual gives an introduction to mpmath's major features. Some supplementary documentation, FAQs, additional examples, etc may be available on the mpmath website.</p>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id2" id="basics" name="basics">2&nbsp;&nbsp;&nbsp;Basics</a></h1>
<p>For download and installation instructions, please refer to the README or the mpmath website (in most cases, installation should be as simple as running <tt class="docutils literal"><span class="pre">python</span> <span class="pre">easy_install</span> <span class="pre">mpmath</span></tt>). After the setup has completed, you can fire up the interactive Python interpreter and try the following:</p>
<pre class="literal-block">
&gt;&gt;&gt; from mpmath import *
&gt;&gt;&gt; mp.dps = 50
&gt;&gt;&gt; print mpf(2) ** mpf('0.5')
1.4142135623730950488016887242096980785696718753769
&gt;&gt;&gt; print 2*pi
6.2831853071795864769252867665590057683943387987502
</pre>
<p>In all interactive code examples that follow, it will be assumed that the main contents of the <tt class="docutils literal"><span class="pre">mpmath</span></tt> package have been imported with &quot;<tt class="docutils literal"><span class="pre">import</span> <span class="pre">*</span></tt>&quot;.</p>
<div class="section">
<h2><a class="toc-backref" href="#id3" id="mpmath-numbers" name="mpmath-numbers">2.1&nbsp;&nbsp;&nbsp;Mpmath numbers</a></h2>
<p>Mpmath provides two main numerical types: <tt class="docutils literal"><span class="pre">mpf</span></tt> and <tt class="docutils literal"><span class="pre">mpc</span></tt>. The <tt class="docutils literal"><span class="pre">mpf</span></tt> type is analogous to Python's built-in <tt class="docutils literal"><span class="pre">float</span></tt>. It holds a real number or one of the special values <tt class="docutils literal"><span class="pre">inf</span></tt> (positive infinity), <tt class="docutils literal"><span class="pre">-inf</span></tt> and <tt class="docutils literal"><span class="pre">nan</span></tt> (not-a-number, indicating an indeterminate result). You can create <tt class="docutils literal"><span class="pre">mpf</span></tt> instances from strings, integers, floats, and other <tt class="docutils literal"><span class="pre">mpf</span></tt> instances:</p>
<pre class="literal-block">
&gt;&gt;&gt; mpf(4)
mpf('4.0')
&gt;&gt;&gt; mpf(2.5)
mpf('2.5')
&gt;&gt;&gt; mpf(&quot;1.25e6&quot;)
mpf('1250000.0')
&gt;&gt;&gt; mpf(mpf(2))
mpf('2.0')
&gt;&gt;&gt; mpf(&quot;inf&quot;)
mpf('+inf')
</pre>
<p>An <tt class="docutils literal"><span class="pre">mpc</span></tt> represents a complex number in rectangular form as a pair of <tt class="docutils literal"><span class="pre">mpf</span></tt> instances. It can be constructed from a Python <tt class="docutils literal"><span class="pre">complex</span></tt>, a real number, or a pair of real numbers:</p>
<pre class="literal-block">
&gt;&gt;&gt; mpc(2,3)
mpc(real='2.0', imag='3.0')
&gt;&gt;&gt; mpc(complex(2,3)).imag
mpf('3.0')
</pre>
<p>You can mix <tt class="docutils literal"><span class="pre">mpf</span></tt> and <tt class="docutils literal"><span class="pre">mpc</span></tt> instances with each other and with Python numbers:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 15
&gt;&gt;&gt; mpf(3) + 2*mpf('2.5') + 1.0
mpf('9.0')
&gt;&gt;&gt; mpc(1j)**0.5
mpc(real='0.70710678118654757', imag='0.70710678118654757')
</pre>
<p>Prettier output can be obtained by using <tt class="docutils literal"><span class="pre">str()</span></tt> or <tt class="docutils literal"><span class="pre">print</span></tt>, which hide the <tt class="docutils literal"><span class="pre">mpf</span></tt> and <tt class="docutils literal"><span class="pre">mpc</span></tt> constructor signatures and suppress small rounding artifacts:</p>
<pre class="literal-block">
&gt;&gt;&gt; mpf(&quot;3.14159&quot;)
mpf('3.1415899999999999')
&gt;&gt;&gt; print mpf(&quot;3.14159&quot;)
3.14159
&gt;&gt;&gt; print mpc(1j)**0.5
(0.707106781186548 + 0.707106781186548j)
</pre>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id4" id="setting-the-precision" name="setting-the-precision">2.2&nbsp;&nbsp;&nbsp;Setting the precision</a></h2>
<p>Mpmath uses a global working precision; it does not keep track of the precision or accuracy of individual numbers. Performing an arithmetic operation or calling <tt class="docutils literal"><span class="pre">mpf()</span></tt> rounds the result to the current working precision. The working precision is controlled by a special object called <tt class="docutils literal"><span class="pre">mp</span></tt>, which has the following default state:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp
Mpmath settings:
  mp.prec = 53                [default: 53]
  mp.dps = 15                 [default: 15]
  mp.rounding = 'nearest'     [default: 'nearest']
</pre>
<p>The term <strong>prec</strong> denotes the binary precision (measured in bits) while <strong>dps</strong> (short for <em>decimal places</em>) is the decimal precision. Binary and decimal precision are related roughly according to the formula <tt class="docutils literal"><span class="pre">prec</span> <span class="pre">=</span> <span class="pre">3.33*dps</span></tt>. For example, it takes a precision of roughly 333 bits to hold an approximation of pi that is accurate to 100 decimal places (actually slightly more than 333 bits is used).</p>
<p>The valid rounding modes are <tt class="docutils literal"><span class="pre">&quot;nearest&quot;</span></tt>, <tt class="docutils literal"><span class="pre">&quot;up&quot;</span></tt>, <tt class="docutils literal"><span class="pre">&quot;down&quot;</span></tt>, <tt class="docutils literal"><span class="pre">&quot;floor&quot;</span></tt>, and <tt class="docutils literal"><span class="pre">&quot;ceiling&quot;</span></tt>. These modes are described in more detail in the section on rounding below. The default rounding mode (round to nearest) is the best setting for most purposes.</p>
<p>Changing either precision property of the <tt class="docutils literal"><span class="pre">mp</span></tt> object automatically updates the other; usually you just want to change the <tt class="docutils literal"><span class="pre">dps</span></tt> value:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 100
&gt;&gt;&gt; mp.dps
100
&gt;&gt;&gt; mp.prec
336
</pre>
<p>When the precision has been set, all <tt class="docutils literal"><span class="pre">mpf</span></tt> operations are carried out at that precision:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 50
&gt;&gt;&gt; mpf(1) / 6
mpf('0.16666666666666666666666666666666666666666666666666656')
&gt;&gt;&gt; mp.dps = 25
&gt;&gt;&gt; mpf(2) ** mpf('0.5')
mpf('1.414213562373095048801688713')
</pre>
<p>The precision of complex arithmetic is also controlled by the <tt class="docutils literal"><span class="pre">mp</span></tt> object:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 10
&gt;&gt;&gt; mpc(1,2) / 3
mpc(real='0.3333333333321', imag='0.6666666666642')
</pre>
<p>The number of digits with which numbers are printed by default is determined by the working precision. To specify the number of digits to show without changing the working precision, use the <tt class="docutils literal"><span class="pre">nstr</span></tt> and <tt class="docutils literal"><span class="pre">nprint</span></tt> functions:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 15
&gt;&gt;&gt; a = mpf(1) / 6
&gt;&gt;&gt; a
mpf('0.16666666666666666')
&gt;&gt;&gt; nstr(a, 8)
'0.16666667'
&gt;&gt;&gt; nprint(a, 8)
0.16666667
&gt;&gt;&gt; nstr(a, 50)
'0.16666666666666665741480812812369549646973609924316'
</pre>
<p>There is no restriction on the magnitude of numbers. An <tt class="docutils literal"><span class="pre">mpf</span></tt> can for example hold an approximation of a large Mersenne prime:</p>
<pre class="literal-block">
&gt;&gt;&gt; print mpf(2)**32582657 - 1
1.24575026015369e+9808357
</pre>
<p>Or why not 1 googolplex:</p>
<pre class="literal-block">
&gt;&gt;&gt; print mpf(10) ** (10**100)  # doctest:+ELLIPSIS
1.0e+100000000000000000000000000000000000000000000000000...
</pre>
<p>The (binary) exponent is stored exactly and is independent of the precision.</p>
<div class="section">
<h3><a id="temporarily-changing-the-precision" name="temporarily-changing-the-precision">2.2.1&nbsp;&nbsp;&nbsp;Temporarily changing the precision</a></h3>
<p>It is often useful to change the precision during only part of a calculation. A way to temporarily increase the precision and then restore it is as follows:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.prec += 2
&gt;&gt;&gt; # do_something()
&gt;&gt;&gt; mp.prec -= 2
</pre>
<p>In Python 2.5, the <tt class="docutils literal"><span class="pre">with</span></tt> statement along with the mpmath functions <tt class="docutils literal"><span class="pre">workprec</span></tt>, <tt class="docutils literal"><span class="pre">workdps</span></tt>, <tt class="docutils literal"><span class="pre">extraprec</span></tt> and <tt class="docutils literal"><span class="pre">extradps</span></tt> can be used to temporarily change precision in a more safe manner:</p>
<pre class="literal-block">
&gt;&gt;&gt; from __future__ import with_statement
&gt;&gt;&gt; with workdps(20):  # doctest: +SKIP
...     print mpf(1)/7
...     with extradps(10):
...         print mpf(1)/7
...
0.14285714285714285714
0.142857142857142857142857142857
&gt;&gt;&gt; mp.dps
15
</pre>
<p>The <tt class="docutils literal"><span class="pre">with</span></tt> statement ensures that the precision gets reset when exiting the block, even in the case that an exception is raised. (The effect of the <tt class="docutils literal"><span class="pre">with</span></tt> statement can be emulated in Python 2.4 by using a <tt class="docutils literal"><span class="pre">try/finally</span></tt> block.)</p>
<p>The <tt class="docutils literal"><span class="pre">workprec</span></tt> family of functions can also be used as function decorators:</p>
<pre class="literal-block">
&gt;&gt;&gt; &#64;workdps(6)
... def f():
...     return mpf(1)/3
...
&gt;&gt;&gt; f()
mpf('0.33333331346511841')
</pre>
</div>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id5" id="providing-correct-input" name="providing-correct-input">2.3&nbsp;&nbsp;&nbsp;Providing correct input</a></h2>
<p>Note that when creating a new <tt class="docutils literal"><span class="pre">mpf</span></tt>, the value will at most be as accurate as the input. <strong>Be careful when mixing mpmath numbers with Python floats</strong>. When working at high precision, fractional <tt class="docutils literal"><span class="pre">mpf</span></tt> values should be created from strings or integers:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 30
&gt;&gt;&gt; mpf(10.9)   # bad
mpf('10.9000000000000003552713678800501')
&gt;&gt;&gt; mpf('10.9')  # good
mpf('10.8999999999999999999999999999997')
&gt;&gt;&gt; mpf(109) / mpf(10)   # also good
mpf('10.8999999999999999999999999999997')
</pre>
<p>(Binary fractions such as 0.5, 1.5, 0.75, 0.125, etc, are generally safe as input, however, since those can be represented exactly by Python floats.)</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id6" id="special-numbers" name="special-numbers">2.4&nbsp;&nbsp;&nbsp;Special numbers</a></h2>
<p>Mpmath provides several special numbers, which are summarized in the following table.</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="80%" />
</colgroup>
<tbody valign="top">
<tr><td>Symbol</td>
<td>Description</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">j</span></tt></td>
<td>Imaginary unit</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">inf</span></tt></td>
<td>Positive infinity</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">-inf</span></tt></td>
<td>Negative infinity</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">nan</span></tt></td>
<td>Not-a-number</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">pi</span></tt></td>
<td>pi = 3.14159</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">degree</span></tt></td>
<td>1 deg = pi/180 = 0.0174532</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">e</span></tt></td>
<td>Base of the natural logarithm, e = 2.71828</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">euler</span></tt></td>
<td>Euler's constant, gamma = 0.577216</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">catalan</span></tt></td>
<td>Catalan's constant, C or K = 0.915966</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">ln2</span></tt></td>
<td>log(2) = 0.693147</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">ln10</span></tt></td>
<td>log(10) = 2.30259</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">eps</span></tt></td>
<td>Epsilon of working precision</td>
</tr>
</tbody>
</table>
<p>The first four objects (<tt class="docutils literal"><span class="pre">j</span></tt>, <tt class="docutils literal"><span class="pre">inf</span></tt>, <tt class="docutils literal"><span class="pre">-inf</span></tt>, <tt class="docutils literal"><span class="pre">nan</span></tt>) are merely shortcuts to <tt class="docutils literal"><span class="pre">mpc</span></tt> and <tt class="docutils literal"><span class="pre">mpf</span></tt> instances with these fixed values.</p>
<p>The remaining numbers are lazy implementations of numerical constants that can be computed with any precision. Whenever the objects are used as function arguments or as operands in arithmetic operations, they automagically evaluate to the current working precision. A lazy number can be converted to a regular <tt class="docutils literal"><span class="pre">mpf</span></tt> using the unary <tt class="docutils literal"><span class="pre">+</span></tt> operator:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 15
&gt;&gt;&gt; pi
&lt;pi: 3.14159~&gt;
&gt;&gt;&gt; 2*pi
mpf('6.2831853071795862')
&gt;&gt;&gt; +pi
mpf('3.1415926535897931')
&gt;&gt;&gt; mp.dps = 40
&gt;&gt;&gt; pi
&lt;pi: 3.14159~&gt;
&gt;&gt;&gt; 2*pi
mpf('6.283185307179586476925286766559005768394338')
&gt;&gt;&gt; +pi
mpf('3.141592653589793238462643383279502884197169')
</pre>
<p>The special number <tt class="docutils literal"><span class="pre">eps</span></tt> is defined as the difference between 1 and the smallest floating-point number after 1 that can be represented with the current working precision:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 15
&gt;&gt;&gt; eps
&lt;epsilon of working precision: 2.22045e-16~&gt;
&gt;&gt;&gt; 1 + eps
mpf('1.0000000000000002')
&gt;&gt;&gt; 1 + eps/2    # Too small to make a difference
mpf('1.0')
&gt;&gt;&gt;
&gt;&gt;&gt; mp.dps = 100
&gt;&gt;&gt; eps
&lt;epsilon of working precision: 1.42873e-101~&gt;
</pre>
<p>An useful application of <tt class="docutils literal"><span class="pre">eps</span></tt> is to perform approximate comparisons that work at any precision level, for example to check for convergence of iterative algorithms:</p>
<pre class="literal-block">
&gt;&gt;&gt; def a_series():
...     s = 0
...     n = 1
...     while 1:
...         term = mpf(5) ** (-n)
...         s += term
...         if term &lt; eps:
...             print &quot;added&quot;, n, &quot;terms&quot;
...             return s
...         n += 1
...
&gt;&gt;&gt; mp.dps = 15
&gt;&gt;&gt; a_series()
added 23 terms
mpf('0.25000000000000011')
&gt;&gt;&gt;
&gt;&gt;&gt; mp.dps = 40
&gt;&gt;&gt; a_series()
added 59 terms
mpf('0.2500000000000000000000000000000000000000057')
</pre>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id7" id="mathematical-functions" name="mathematical-functions">2.5&nbsp;&nbsp;&nbsp;Mathematical functions</a></h2>
<p>Mpmath implements the standard functions available in Python's <tt class="docutils literal"><span class="pre">math</span></tt> and <tt class="docutils literal"><span class="pre">cmath</span></tt> modules, for both real and complex numbers and with arbitrary precision:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 25
&gt;&gt;&gt; print cosh('1.234')
1.863033801698422589073644
&gt;&gt;&gt; print asin(1)
1.570796326794896619231322
&gt;&gt;&gt; print log(1+2j)
(0.8047189562170501873003797 + 1.107148717794090503017065j)
&gt;&gt;&gt; print exp(2+3j)
(-7.315110094901102517486536 + 1.042743656235904414101504j)
</pre>
<p>Some functions that do not exist in the standard Python <tt class="docutils literal"><span class="pre">math</span></tt> library are available, such as factorials (with support for noninteger arguments):</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 20
&gt;&gt;&gt; print factorial(10)
3628800.0
&gt;&gt;&gt; print factorial(0.25)
0.90640247705547707798
&gt;&gt;&gt; print factorial(2+3j)
(-0.44011340763700171113 - 0.06363724312631702183j)
</pre>
<p>The list of functions is given in the following table.</p>
<table border="1" class="docutils">
<colgroup>
<col width="24%" />
<col width="76%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Function</th>
<th class="head">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr><td><tt class="docutils literal"><span class="pre">sqrt(x)</span></tt></td>
<td>Square root</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">hypot(x,y)</span></tt></td>
<td>Euclidean norm</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">exp(x)</span></tt></td>
<td>Exponential function</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">log(x,b)</span></tt></td>
<td>Natural logarithm (optionally base-b logarithm)</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">power(x,y)</span></tt></td>
<td>Power, x^y</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">cos(x)</span></tt></td>
<td>Cosine</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">sin(x)</span></tt></td>
<td>Sine</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">tan(x)</span></tt></td>
<td>Tangent</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">cosh(x)</span></tt></td>
<td>Hyperbolic cosine</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">sinh(x)</span></tt></td>
<td>Hyperbolic sine</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">tanh(x)</span></tt></td>
<td>Hyperbolic tangent</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">acos(x)</span></tt></td>
<td>Inverse cosine</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">asin(x)</span></tt></td>
<td>Inverse sine</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">atan(x)</span></tt></td>
<td>Inverse tangent</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">atan2(y,x)</span></tt></td>
<td>Inverse tangent atan(y/x) with attention to signs of both x and y</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">acosh(x)</span></tt></td>
<td>Inverse hyperbolic cosine</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">asinh(x)</span></tt></td>
<td>Inverse hyperbolic sine</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">atanh(x)</span></tt></td>
<td>Inverse hyperbolic tangent</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">floor(x)</span></tt></td>
<td>Floor function (round to integer in the direction of -inf)</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">ceil(x)</span></tt></td>
<td>Ceiling function (round to integer in the direction of +inf)</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">arg(x)</span></tt></td>
<td>Complex argument</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">rand()</span></tt></td>
<td>Generate a random number in [0, 1)</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">factorial(x)</span></tt></td>
<td>Factorial</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">gamma(x)</span></tt></td>
<td>Gamma function</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">lower_gamma(a,x)</span></tt></td>
<td>Lower gamma function</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">upper_gamma(a,x)</span></tt></td>
<td>Upper gamma function</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">erf(x)</span></tt></td>
<td>Error function</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">zeta(x)</span></tt></td>
<td>Riemann zeta function</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">j0(x)</span></tt></td>
<td>Bessel function J_0(x)</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">j1(x)</span></tt></td>
<td>Bessel function J_1(x)</td>
</tr>
<tr><td><tt class="docutils literal"><span class="pre">jn(n,x)</span></tt></td>
<td>Bessel function J_n(x)</td>
</tr>
</tbody>
</table>
<p>The following functions do not accept complex input: <tt class="docutils literal"><span class="pre">hypot</span></tt>, <tt class="docutils literal"><span class="pre">atan2</span></tt>, <tt class="docutils literal"><span class="pre">floor</span></tt>, <tt class="docutils literal"><span class="pre">ceil</span></tt>, <tt class="docutils literal"><span class="pre">j0</span></tt>, <tt class="docutils literal"><span class="pre">j1</span></tt> and <tt class="docutils literal"><span class="pre">jn</span></tt>.</p>
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id8" id="high-level-features" name="high-level-features">3&nbsp;&nbsp;&nbsp;High-level features</a></h1>
<div class="section">
<h2><a class="toc-backref" href="#id9" id="integration" name="integration">3.1&nbsp;&nbsp;&nbsp;Integration</a></h2>
<p>The function <tt class="docutils literal"><span class="pre">quadts</span></tt> performs numerical integration (quadrature) using the tanh-sinh algorithm. The syntax for integrating a function <em>f</em> between the endpoints <em>a</em> and <em>b</em> is <tt class="docutils literal"><span class="pre">quadts(f,</span> <span class="pre">a,</span> <span class="pre">b)</span></tt>. For example:</p>
<pre class="literal-block">
&gt;&gt;&gt; print quadts(sin, 0, pi)
2.0
</pre>
<p>Tanh-sinh quadrature is extremely efficient for high-precision integration of analytic functions. Unlike the more well-known Gaussian quadrature algorithm, it is relatively insensitive to integrable singularities at the endpoints of the interval. The <tt class="docutils literal"><span class="pre">quadts</span></tt> function attempts to evaluate the integral to the full working precision; for example, it can calculate 100 digits of pi by integrating the area under the half circle arc <tt class="docutils literal"><span class="pre">x^2</span> <span class="pre">+</span> <span class="pre">y^2</span> <span class="pre">=</span> <span class="pre">1</span> <span class="pre">(y</span> <span class="pre">&gt;</span> <span class="pre">0)</span></tt>:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 100
&gt;&gt;&gt; print quadts(lambda x: 2*sqrt(1 - x**2), -1, 1)
... # doctest:+ELLIPSIS
3.14159265358979323846264338327950288419716939937510582097...
</pre>
<p>The tanh-sinh scheme is efficient enough that analytic 100-digit integrals like this one can often be evaluated in less than a second. The timings for computing this integral at various precision levels on the author's computer is:</p>
<table border="1" class="docutils">
<colgroup>
<col width="12%" />
<col width="43%" />
<col width="45%" />
</colgroup>
<tbody valign="top">
<tr><td>dps</td>
<td>First evaluation</td>
<td>Second evaluation</td>
</tr>
<tr><td>15</td>
<td>0.029 seconds</td>
<td>0.0060 seconds</td>
</tr>
<tr><td>50</td>
<td>0.15 seconds</td>
<td>0.016 seconds</td>
</tr>
<tr><td>500</td>
<td>16.3 seconds</td>
<td>0.50 seconds</td>
</tr>
</tbody>
</table>
<p>The second integration at the same precision level is much faster. The reason for this is that the tanh-sinh algorithm must be initalized by computing a set of nodes, and this initalization if often more expensive than actually evaluating the integral. Mpmath automatically caches all computed nodes to make subsequent integrations faster, but the cache is lost when Python shuts down, so if you would frequently like to use mpmath to calculate 1000-digit integrals, you may want to save the nodes to a file. The nodes are stored in a dict <tt class="docutils literal"><span class="pre">TS_cache</span></tt> located in the <tt class="docutils literal"><span class="pre">mpmath.calculus</span></tt> module, which can be pickled if desired.</p>
<div class="section">
<h3><a id="features-and-application-examples" name="features-and-application-examples">3.1.1&nbsp;&nbsp;&nbsp;Features and application examples</a></h3>
<p>You can integrate over infinite or half-infinite intervals:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 15
&gt;&gt;&gt; print quadts(lambda x: 2/(x**2+1), 0, inf)
3.14159265358979
&gt;&gt;&gt; print quadts(lambda x: exp(-x**2), -inf, inf)**2
3.14159265358979
</pre>
<p>Complex integrals are also supported. The next example computes Euler's constant gamma by using Cauchy's integral formula and looking at the pole of the Riemann zeta function at <em>z</em> = 1:</p>
<pre class="literal-block">
&gt;&gt;&gt; print 1/(2*pi)*quadts(lambda x: zeta(exp(j*x)+1), 0, 2*pi)
(0.577215664901533 + 2.86444093843177e-25j)
</pre>
<p>Functions with integral representations, such as the gamma function, can be implemented directly from the definition:</p>
<pre class="literal-block">
&gt;&gt;&gt; def Gamma(z):
...     return quadts(lambda t: exp(-t)*t**(z-1), 0, inf)
...
&gt;&gt;&gt; print Gamma(1)
1.0
&gt;&gt;&gt; print Gamma(10)
362880.0
&gt;&gt;&gt; print Gamma(1+1j)
(0.498015668118356 - 0.154949828301811j)
</pre>
</div>
<div class="section">
<h3><a id="double-integrals" name="double-integrals">3.1.2&nbsp;&nbsp;&nbsp;Double integrals</a></h3>
<p>It is possible to calculate double integrals with <tt class="docutils literal"><span class="pre">quadts</span></tt>. To do this, simply provide a two-argument function and, instead of two endpoints, provide two intervals. The first interval specifies the range for the <em>x</em> variable and the second interval specifies the range of the <em>y</em> variable:</p>
<pre class="literal-block">
&gt;&gt;&gt; f = lambda x, y: cos(x+y/2)
&gt;&gt;&gt; print quadts(f, (-pi/2, pi/2), (0, pi))
4.0
</pre>
<p>Here are some more difficult examples taken from <a class="reference" href="http://mathworld.wolfram.com/DoubleIntegral.html">MathWorld</a> (all except the second contain corner singularities):</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 30
&gt;&gt;&gt; f = lambda x, y: (x-1)/((1-x*y)*log(x*y))
&gt;&gt;&gt; print quadts(f, (0, 1), (0, 1))
0.577215664901532860606512090082
&gt;&gt;&gt; print euler
0.577215664901532860606512090082

&gt;&gt;&gt; f = lambda x, y: 1/sqrt(1+x**2+y**2)
&gt;&gt;&gt; print quadts(f, (-1, 1), (-1, 1))
3.17343648530607134219175646705
&gt;&gt;&gt; print 4*log(2+sqrt(3))-2*pi/3
3.17343648530607134219175646705

&gt;&gt;&gt; f = lambda x, y: 1/(1-x**2 * y**2)
&gt;&gt;&gt; print quadts(f, (0, 1), (0, 1))
1.23370055013616982735431137498
&gt;&gt;&gt; print pi**2 / 8
1.23370055013616982735431137498

&gt;&gt;&gt; print quadts(lambda x, y: 1/(1-x*y), (0, 1), (0, 1))
1.64493406684822643647241516665
&gt;&gt;&gt; print pi**2 / 6
1.64493406684822643647241516665
</pre>
<p>There is currently no direct support for computing triple or higher dimensional integrals; if desired, this can be done easily by passing a function that calls <tt class="docutils literal"><span class="pre">quadts</span></tt> recursively:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 15
&gt;&gt;&gt; f = lambda x, y: quadts(lambda z: sin(x)/z+y*z, 1, 2)
&gt;&gt;&gt; print quadts(f, (1, 2), (1, 2))
2.91296002641413
&gt;&gt;&gt; print mpf(9)/4 + (cos(1)-cos(2))*log(2)
2.91296002641413
</pre>
<p>While double integrals are reasonably fast, even a simple triple integral at very low precision is likely to take several seconds to evaluate (harder integrals may take minutes). A quadruple integral will require a whole lot of patience.</p>
</div>
<div class="section">
<h3><a id="error-detection" name="error-detection">3.1.3&nbsp;&nbsp;&nbsp;Error detection</a></h3>
<p>The tanh-sinh algorithm is not suitable for adaptive quadrature, and does not perform well if there are singularities between the endpoints or if the integrand is very bumpy or oscillatory (such integrals should manually be split into smaller pieces). If the <tt class="docutils literal"><span class="pre">error</span></tt> option is set, <tt class="docutils literal"><span class="pre">quadts</span></tt> will return an error estimate along with the result; although this estimate is not always correct, it can be useful for debugging. You can also pass <tt class="docutils literal"><span class="pre">quadts</span></tt> the option <tt class="docutils literal"><span class="pre">verbose=True</span></tt> to show detailed progress.</p>
<p>A simple example where the algorithm fails is the function f(<em>x</em>) = abs(sin(<em>x</em>)), which is not smooth at <em>x</em> = pi. In this case, a close value is calculated, but the result is nowhere near the target accuracy; however, <tt class="docutils literal"><span class="pre">quadts</span></tt> gives a good estimate of the magnitude of the error:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 15
&gt;&gt;&gt; quadts(lambda x: abs(sin(x)), 0, 2*pi, error=True)
(mpf('3.9990089417677899'), mpf('0.001'))
</pre>
<p>Attempting to evaluate oscillatory integrals on large intervals by means of the tanh-sinh method is generally futile. This integral should be pi/2 = 1.57:</p>
<pre class="literal-block">
&gt;&gt;&gt; print quadts(lambda x: sin(x)/x, 0, inf, error=True)
(mpf('2.3840907358976544'), mpf('1.0'))
</pre>
<p>The next integral should be approximately 0.627 but <tt class="docutils literal"><span class="pre">quadts</span></tt> generates complete nonsense both in the result and the error estimate (the error estimate is somewhat arbitrarily capped at 1.0):</p>
<pre class="literal-block">
&gt;&gt;&gt; print quadts(lambda x: sin(x**2), 0, inf, error=True)
(mpf('2.5190134849122411e+21'), mpf('1.0'))
</pre>
<p>However, oscillation is not a problem if suppressed by sufficiently fast (preferrably exponential) decay. This integral is exactly 1/2:</p>
<pre class="literal-block">
&gt;&gt;&gt; print quadts(lambda x: exp(-x)*sin(x), 0, inf)
0.5
</pre>
<p>Another illustrative example is the following double integral, which <tt class="docutils literal"><span class="pre">quadts</span></tt> will process for several seconds before returning a value with very low accuracy:</p>
<pre class="literal-block">
&gt;&gt;&gt; mpf.dps = 15
&gt;&gt;&gt; f = lambda x, y: sqrt((x-0.5)**2+(y-0.5)**2)
&gt;&gt;&gt; quadts(f, (0, 1), (0, 1), error=1)
(mpf('0.38259743528830826'), mpf('1.0e-6'))
</pre>
<p>The problem is due to the non-analytic behavior of the function at the midpoint (1/2, 1/2). We can do much better by splitting the area into four pieces (because of the symmetry, we only need to evaluate one of them):</p>
<pre class="literal-block">
&gt;&gt;&gt; f = lambda x, y: 4*sqrt((x-0.5)**2 + (y-0.5)**2)
&gt;&gt;&gt; print quadts(f, (0.5, 1), (0.5, 1))
0.382597858232106
&gt;&gt;&gt; print (sqrt(2) + asinh(1))/6
0.382597858232106
</pre>
<p>The value agrees with the known answer and the running time in this case is just 0.7 seconds on the author's computer.</p>
<p>Even for analytic integrals on finite intervals, there is no guarantee that <tt class="docutils literal"><span class="pre">quadts</span></tt> will be successful. A few examples of integrals for which <tt class="docutils literal"><span class="pre">quadts</span></tt> currently fails to reach full accuracy are:</p>
<pre class="literal-block">
quadts(lambda x: sqrt(tan(x)), 0, pi/2)
quadts(lambda x: atan(x)/(x*sqrt(1-x**2)), 0, 1)
quadts(lambda x: log(1+x**2)/x**2, 0, 1)
quadts(lambda x: x**2/((1+x**4)*sqrt(1-x**4)), 0, 1)
</pre>
<p>(It is possible that future improvements to the <tt class="docutils literal"><span class="pre">quadts</span></tt> implementation will make these particular examples work.)</p>
</div>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id10" id="differentiation" name="differentiation">3.2&nbsp;&nbsp;&nbsp;Differentiation</a></h2>
<p>The function <tt class="docutils literal"><span class="pre">diff</span></tt> computes a derivative of a given function. It uses a simple two-point finite difference approximation, but increases the working precision to get good results. The step size is chosen roughly equal to the <tt class="docutils literal"><span class="pre">eps</span></tt> of the working precision, and the function values are computed at twice the working precision; for reasonably smooth functions, this typically gives full accuracy:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 15
&gt;&gt;&gt; print diff(cos, 1)
-0.841470984807897
&gt;&gt;&gt; print -sin(1)
-0.841470984807897
</pre>
<p>One-sided derivatives can be computed by specifying the <tt class="docutils literal"><span class="pre">direction</span></tt> parameter. With <tt class="docutils literal"><span class="pre">direction</span> <span class="pre">=</span> <span class="pre">0</span></tt> (default), <tt class="docutils literal"><span class="pre">diff</span></tt> uses a central difference (<tt class="docutils literal"><span class="pre">f(x-h)</span></tt>, <tt class="docutils literal"><span class="pre">f(x+h)</span></tt>). With <tt class="docutils literal"><span class="pre">direction</span> <span class="pre">=</span> <span class="pre">1</span></tt>, it uses a forward difference (<tt class="docutils literal"><span class="pre">f(x)</span></tt>, <tt class="docutils literal"><span class="pre">f(x+h)</span></tt>), and with <tt class="docutils literal"><span class="pre">direction</span> <span class="pre">=</span> <span class="pre">-1</span></tt>, a backward difference (<tt class="docutils literal"><span class="pre">f(x-h)</span></tt>, <tt class="docutils literal"><span class="pre">f(x)</span></tt>):</p>
<pre class="literal-block">
&gt;&gt;&gt; print diff(abs, 0, direction=0)
0.0
&gt;&gt;&gt; print diff(abs, 0, direction=1)
1.0
&gt;&gt;&gt; print diff(abs, 0, direction=-1)
-1.0
</pre>
<p>Although the finite difference approximation can be applied recursively to compute <em>n</em>-th order derivatives, this is inefficient for large <em>n</em> since <tt class="docutils literal"><span class="pre">2^n</span></tt> evaluation points are required, using <tt class="docutils literal"><span class="pre">2^n</span></tt>-fold extra precision. As an alternative, the function <tt class="docutils literal"><span class="pre">diffc</span></tt> computes derivatives of arbitrary order by means of complex contour integration. It is for example able to compute a 13th-order derivative of sin (here at <em>x</em> = 0):</p>
<pre class="literal-block">
&gt;&gt;&gt; print diffc(sin, 0, 13)
(0.999998702480854 + 6.05532349899064e-13j)
</pre>
<p>The accuracy can be improved by increasing the radius of the integration contour (provided that the function is well-behaved within this region):</p>
<pre class="literal-block">
&gt;&gt;&gt; print diffc(sin, 0, 13, radius=5)
(1.0 - 3.3608728322706e-23j)
</pre>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id11" id="root-finding" name="root-finding">3.3&nbsp;&nbsp;&nbsp;Root-finding</a></h2>
<p>The function <tt class="docutils literal"><span class="pre">secant</span></tt> locates a root of a given function using the secant method. A simple example use of the secant method is to compute pi as the root of sin(<em>x</em>) closest to <em>x</em> = 3:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 30
&gt;&gt;&gt; print secant(sin, 3)
3.14159265358979323846264338328
</pre>
<p>The secant method can be used to find complex roots of analytic functions, although it must in that case generally be given a nonreal starting value (or else it will never leave the real line):</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 15
&gt;&gt;&gt; print secant(lambda x: x**3 + 2*x + 1, j)
(0.226698825758202 + 1.46771150871022j)
</pre>
<p>A good initial guess for the location of the root is required for the method to be effective, so it is somewhat more appropriate to think of the secant method as a root-polishing method than a root-finding method. When the rough location of the root is known, the secant method can be used to refine it to very high precision in only a few steps. If the root is a first-order root, only roughly log(prec) iterations are required. (The secant method is far less efficient for double roots.) It may be worthwhile to compute the initial approximation to a root using a machine precision solver (for example using one of SciPy's many solvers), and then refining it to high precision using mpmath's <tt class="docutils literal"><span class="pre">secant</span></tt> method.</p>
<div class="section">
<h3><a id="applications" name="applications">3.3.1&nbsp;&nbsp;&nbsp;Applications</a></h3>
<p>A nice application is to compute nontrivial roots of the Riemann zeta function with many digits (good initial values are needed for convergence):</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 30
&gt;&gt;&gt; print secant(zeta, 0.5+14j)
(0.5 + 14.1347251417346937904572519836j)
</pre>
<p>The secant method can also be used as an optimization algorithm, by passing it a derivative of a function. The following example locates the positive minimum of the gamma function:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 20
&gt;&gt;&gt; print secant(lambda x: diff(gamma, x), 1)
1.4616321449683623413
</pre>
<p>Finally, a useful application is to compute inverse functions, such as the Lambert W function which is the inverse of <em>w</em> exp(<em>w</em>), given the first term of the solution's asymptotic expansion as the initial value:</p>
<pre class="literal-block">
&gt;&gt;&gt; def lambert(x):
...     return secant(lambda w: w*exp(w) - x, log(1+x))
...
&gt;&gt;&gt; mp.dps = 15
&gt;&gt;&gt; print lambert(1)
0.567143290409784
&gt;&gt;&gt; print lambert(1000)
5.2496028524016
</pre>
</div>
<div class="section">
<h3><a id="options" name="options">3.3.2&nbsp;&nbsp;&nbsp;Options</a></h3>
<p>Strictly speaking, the secant method requires two initial values. By default, you only have to provide the first point <tt class="docutils literal"><span class="pre">x0</span></tt>; <tt class="docutils literal"><span class="pre">secant</span></tt> automatically sets the second point (somewhat arbitrarily) to <tt class="docutils literal"><span class="pre">x0</span> <span class="pre">+</span> <span class="pre">1/4</span></tt>. Manually providing also the second point can help in some cases if <tt class="docutils literal"><span class="pre">secant</span></tt> fails to converge.</p>
<p>By default, <tt class="docutils literal"><span class="pre">secant</span></tt> performs a maximum of 20 steps, which can be increased or decreased using the <tt class="docutils literal"><span class="pre">maxsteps</span></tt> keyword argument. You can pass <tt class="docutils literal"><span class="pre">secant</span></tt> the option <tt class="docutils literal"><span class="pre">verbose=True</span></tt> to show detailed progress.</p>
</div>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id12" id="polynomials" name="polynomials">3.4&nbsp;&nbsp;&nbsp;Polynomials</a></h2>
<div class="section">
<h3><a id="polynomial-evaluation" name="polynomial-evaluation">3.4.1&nbsp;&nbsp;&nbsp;Polynomial evaluation</a></h3>
<p>Polynomial functions can be evaluated using <tt class="docutils literal"><span class="pre">polyval</span></tt>, which takes as input a list of coefficients and the desired evaluation point. The following example evaluates <tt class="docutils literal"><span class="pre">2</span> <span class="pre">+</span> <span class="pre">5*x</span> <span class="pre">+</span> <span class="pre">x^3</span></tt> at <tt class="docutils literal"><span class="pre">x</span> <span class="pre">=</span> <span class="pre">3.5</span></tt>:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 20
&gt;&gt;&gt; polyval([2, 5, 0, 1], mpf('3.5'))
mpf('62.375')
</pre>
<p>With <tt class="docutils literal"><span class="pre">derivative=True</span></tt>, both the polynomial and its derivative are evaluated at the same point:</p>
<pre class="literal-block">
&gt;&gt;&gt; polyval([2, 5, 0, 1], mpf('3.5'), derivative=True)
(mpf('62.375'), mpf('41.75'))
</pre>
<p>The point and coefficients may be complex numbers.</p>
</div>
<div class="section">
<h3><a id="finding-roots-of-polynomials" name="finding-roots-of-polynomials">3.4.2&nbsp;&nbsp;&nbsp;Finding roots of polynomials</a></h3>
<p>The function <tt class="docutils literal"><span class="pre">polyroots</span></tt> computes all <em>n</em> real or complex roots of an <em>n</em>-th degree polynomial using complex arithmetic, and returns them along with an error estimate. As a simple example, it will successfully compute the two real roots of <tt class="docutils literal"><span class="pre">3*x^2</span> <span class="pre">-</span> <span class="pre">7*x</span> <span class="pre">+</span> <span class="pre">2</span></tt> (which are 1/3 and 2):</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 15
&gt;&gt;&gt; roots, err = polyroots([2, -7, 3])
&gt;&gt;&gt; print err
2.66453525910038e-16
&gt;&gt;&gt; for root in roots:
...     print root
...
(0.333333333333333 - 9.62964972193618e-35j)
(2.0 + 1.5395124730131e-50j)
</pre>
<p>As should be expected from the internal use of complex arithmetic, the calculated roots have small but nonzero imaginary parts.</p>
<p>The following example computes all the 5th roots of unity; i.e. the roots of <tt class="docutils literal"><span class="pre">x^5</span> <span class="pre">-</span> <span class="pre">1</span></tt>:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 20
&gt;&gt;&gt; for a in polyroots([-1, 0, 0, 0, 0, 1])[0]:
...     print a
...
(-0.8090169943749474241 + 0.58778525229247312917j)
(1.0 + 0.0j)
(0.3090169943749474241 + 0.95105651629515357212j)
(-0.8090169943749474241 - 0.58778525229247312917j)
(0.3090169943749474241 - 0.95105651629515357212j)
</pre>
</div>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id13" id="interval-arithmetic" name="interval-arithmetic">3.5&nbsp;&nbsp;&nbsp;Interval arithmetic</a></h2>
<p>The <tt class="docutils literal"><span class="pre">mpi</span></tt> type holds an interval defined by a pair of <tt class="docutils literal"><span class="pre">mpf</span></tt> values. Arithmetic on intervals uses conservative rounding so that, if an interval is interpreted as a numerical uncertainty interval for a fixed number, any sequence of interval operations will produce an interval that contains what would be the result of applying the same sequence of operations to the exact number.</p>
<p>You can create an <tt class="docutils literal"><span class="pre">mpi</span></tt> from a number (treated as a zero-width interval) or a pair of numbers. Strings are treated as exact decimal numbers (note that a Python float like 0.1 generally does not represent the same number as its literal; use <tt class="docutils literal"><span class="pre">'0.1'</span></tt> instead):</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 15
&gt;&gt;&gt; mpi(3)
[3.0, 3.0]
&gt;&gt;&gt; mpi(2, 3)
[2.0, 3.0]
&gt;&gt;&gt; mpi(0.1)  # probably not what you want
[0.10000000000000000555, 0.10000000000000000555]
&gt;&gt;&gt; mpi('0.1')  # good
[0.099999999999999991673, 0.10000000000000000555]
</pre>
<p>The fact that <tt class="docutils literal"><span class="pre">'0.1'</span></tt> results in an interval of nonzero width proves that 1/10 cannot be represented using binary floating-point numbers at this precision level (in fact, it cannot be represented exactly at any precision).</p>
<p>Some basic examples of interval arithmetic operations are:</p>
<pre class="literal-block">
&gt;&gt;&gt; mpi(0,1) + 1
[1.0, 2.0]
&gt;&gt;&gt; mpi(0,1) + mpi(4,6)
[4.0, 7.0]
&gt;&gt;&gt; 2 * mpi(2, 3)
[4.0, 6.0]
&gt;&gt;&gt; mpi(-1, 1) * mpi(10, 20)
[-20.0, 20.0]
</pre>
<p>Intervals have the properties <tt class="docutils literal"><span class="pre">.a</span></tt>, <tt class="docutils literal"><span class="pre">.b</span></tt> (endpoints), <tt class="docutils literal"><span class="pre">.mid</span></tt>, and <tt class="docutils literal"><span class="pre">.delta</span></tt> (width):</p>
<pre class="literal-block">
&gt;&gt;&gt; x = mpi(2, 5)
&gt;&gt;&gt; x.a
mpf('2.0')
&gt;&gt;&gt; x.b
mpf('5.0')
&gt;&gt;&gt; x.mid
mpf('3.5')
&gt;&gt;&gt; x.delta
mpf('3.0')
</pre>
<p>Intervals may be infinite or half-infinite:</p>
<pre class="literal-block">
&gt;&gt;&gt; 1 / mpi(2, inf)
[0.0, 0.5]
</pre>
<p>The <tt class="docutils literal"><span class="pre">in</span></tt> operator tests whether a number or interval is contained in another interval:</p>
<pre class="literal-block">
&gt;&gt;&gt; mpi(0, 2) in mpi(0, 10)
True
&gt;&gt;&gt; 3 in mpi(-inf, 0)
False
</pre>
<p>Division is generally not an exact operation in floating-point arithmetic. Using interval arithmetic, we can track both the error from the division and the error that propagates if we follow up with the inverse operation:</p>
<pre class="literal-block">
&gt;&gt;&gt; 1 / mpi(3)
[0.33333333333333331483, 0.33333333333333337034]
&gt;&gt;&gt; 1 / (1 / mpi(3))
[2.9999999999999995559, 3.0000000000000004441]
</pre>
<p>The same goes for computing square roots:</p>
<pre class="literal-block">
&gt;&gt;&gt; (mpi(2) ** 0.5) ** 2
[1.9999999999999995559, 2.0000000000000004441]
</pre>
<p>By design, interval arithmetic propagates errors, no matter how tiny, that would get rounded off in normal floating-point arithmetic:</p>
<pre class="literal-block">
&gt;&gt;&gt; mpi(1) + mpi('1e-10000')
[1.0, 1.000000000000000222]
</pre>
<p>Interval arithmetic uses the same precision as the <tt class="docutils literal"><span class="pre">mpf</span></tt> class; if <tt class="docutils literal"><span class="pre">mp.dps</span> <span class="pre">=</span> <span class="pre">50</span></tt> is set, all interval operations will be carried out with 50-digit precision. Of course, interval arithmetic is guaranteed to give correct bounds at any precision, but a higher precision makes the intervals narrower and hence more accurate:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 5
&gt;&gt;&gt; mpi(pi)
[3.141590118, 3.141593933]
&gt;&gt;&gt; mp.dps = 30
&gt;&gt;&gt; mpi(pi)  # doctest: +ELLIPSIS
[3.14159265358979...793333, 3.14159265358979...797277]
</pre>
<p>It should be noted that the support for interval arithmetic in mpmath is still somewhat primitive, but the standard arithmetic operators <tt class="docutils literal"><span class="pre">+,</span> <span class="pre">-,</span> <span class="pre">*,</span> <span class="pre">/</span></tt>, as well as integer powers should work correctly. It is not currently possible to use functions like <tt class="docutils literal"><span class="pre">sin</span></tt> or <tt class="docutils literal"><span class="pre">log</span></tt> with interval arguments. You can convert mathematical constants to intervals (as in the previous example) and compute fractional powers, but this is not currently guaranteed to give correct results (although it most likely will).</p>
<div class="section">
<h3><a id="establishing-inequalities" name="establishing-inequalities">3.5.1&nbsp;&nbsp;&nbsp;Establishing inequalities</a></h3>
<p>Interval arithmetic can be used to establish inequalities such as <tt class="docutils literal"><span class="pre">exp(pi*sqrt(163))</span> <span class="pre">&lt;</span> <span class="pre">640320**3</span> <span class="pre">+</span> <span class="pre">744</span></tt>. The left-hand and right-hand sides in this inequality agree to over 30 digits, so low-precision arithmetic may give the wrong result:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 25
&gt;&gt;&gt; exp(pi*sqrt(163)) &lt; (640320**3 + 744)
False
</pre>
<p>The answer should be True, but the rounding errors are larger than the difference between the numbers. To get the right answer, we can use interval arithmetic to check the sign of the difference between the two sides of the inequality. Interval arithmetic does not tell us the answer right away if we keep <tt class="docutils literal"><span class="pre">mp.dps</span> <span class="pre">=</span> <span class="pre">25</span></tt>, but it is honest enough to admit it:</p>
<pre class="literal-block">
&gt;&gt;&gt; mpi(e) ** (mpi(pi) * mpi(163)**0.5) - (640320**3 + 744)
... # doctest: +ELLIPSIS
[-0.000000793..., 0.000000946...]
</pre>
<p>There is both a negative and a positive endpoint, so we cannot tell for certain whether the true difference is on one side or the other of zero. The solution is to increase the precision until the answer is strictly one-signed:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 35
&gt;&gt;&gt; mpi(e) ** (mpi(pi) * mpi(163)**0.5) - (640320**3 + 744)
... # doctest: +ELLIPSIS
[-7.499745...e-13, -7.498606...-13]
</pre>
</div>
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id14" id="technical-details" name="technical-details">4&nbsp;&nbsp;&nbsp;Technical details</a></h1>
<p>Doing a high-precision calculation in mpmath typically just amounts to setting the precision and entering a formula. However, some more details of mpmath's terminology and internal number model can be useful to avoid common errors, and is recommended for trying more advanced calculations.</p>
<div class="section">
<h2><a class="toc-backref" href="#id15" id="representation-of-numbers" name="representation-of-numbers">4.1&nbsp;&nbsp;&nbsp;Representation of numbers</a></h2>
<p>Mpmath uses binary arithmetic. A binary floating-point number is a number of the form <tt class="docutils literal"><span class="pre">man</span> <span class="pre">*</span> <span class="pre">2^exp</span></tt> where both <tt class="docutils literal"><span class="pre">man</span></tt> (the <em>mantissa</em>) and <tt class="docutils literal"><span class="pre">exp</span></tt> (the <em>exponent</em>) are integers. Some examples of floating-point numbers are given in the following table.</p>
<blockquote>
<table border="1" class="docutils">
<colgroup>
<col width="29%" />
<col width="36%" />
<col width="36%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Number</th>
<th class="head">Mantissa</th>
<th class="head">Exponent</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>3</td>
<td>3</td>
<td>0</td>
</tr>
<tr><td>10</td>
<td>5</td>
<td>1</td>
</tr>
<tr><td>-16</td>
<td>-1</td>
<td>4</td>
</tr>
<tr><td>1.25</td>
<td>5</td>
<td>-2</td>
</tr>
</tbody>
</table>
</blockquote>
<p>The representation as defined so far is not unique; one can always multiply the mantissa by 2 and subtract 1 from the exponent with no change in the numerical value. In mpmath, numbers are always normalized so that <tt class="docutils literal"><span class="pre">man</span></tt> is an odd number, with the exception of zero which is always taken to have <tt class="docutils literal"><span class="pre">man</span> <span class="pre">=</span> <span class="pre">exp</span> <span class="pre">=</span> <span class="pre">0</span></tt>. With these conventions, every representable number has a unique representation. (Mpmath does not currently distinguish between positive and negative zero.)</p>
<p>Simple mathematical operations are now easy to define. Due to uniqueness, equality testing of two numbers simply amounts to separately checking equality of the mantissas and the exponents. Multiplication of nonzero numbers is straightforward: <tt class="docutils literal"><span class="pre">(m*2^e)</span> <span class="pre">*</span> <span class="pre">(n*2^f)</span> <span class="pre">=</span> <span class="pre">(m*n)</span> <span class="pre">*</span> <span class="pre">2^(e+f)</span></tt>. Addition is a bit more involved: we first need to multiply the mantissa of one of the operands by a suitable power of 2 to obtain equal exponents.</p>
<p>More technically, mpmath represents a floating-point number as a 4-tuple <tt class="docutils literal"><span class="pre">(sign,</span> <span class="pre">man,</span> <span class="pre">exp,</span> <span class="pre">bc)</span></tt> where <cite>sign</cite> is 0 or 1 (indicating positive vs negative) and the mantissa is nonnegative; <tt class="docutils literal"><span class="pre">bc</span></tt> (<em>bitcount</em>) is the size of the absolute value of the mantissa as measured in bits. Though redundant, keeping a separate sign field and explicitly keeping track of the bitcount significantly speeds up arithmetic (the bitcount, especially, is frequently needed but slow to compute from scratch due to the lack of a Python built-in function for the purpose).</p>
<p>The special numbers <tt class="docutils literal"><span class="pre">+inf</span></tt>, <tt class="docutils literal"><span class="pre">-inf</span></tt> and <tt class="docutils literal"><span class="pre">nan</span></tt> are represented internally by a zero mantissa and a nonzero exponent.</p>
<p>For further details on how the arithmetic is implemented, refer to the mpmath source code. The basic arithmetic operations are found in the <tt class="docutils literal"><span class="pre">lib.py</span></tt> module; many functions there are commented extensively.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id16" id="precision-and-accuracy" name="precision-and-accuracy">4.2&nbsp;&nbsp;&nbsp;Precision and accuracy</a></h2>
<p>Contrary to popular superstition, floating-point numbers  do not come with an inherent &quot;small uncertainty&quot;. Every binary floating-point number is an exact rational number. With arbitrary-precision integers used for the mantissa and exponent, floating-point numbers can be added, subtracted and multiplied <em>exactly</em>. In particular, integers and integer multiples of 1/2, 1/4, 1/8, 1/16, etc. can be represented, added and multiplied exactly in binary floating-point.</p>
<p>The reason why floating-point arithmetic is generally approximate is that we set a limit to the size of the mantissa for efficiency reasons. The maximum allowed width (bitcount) of the mantissa is called the precision or <tt class="docutils literal"><span class="pre">prec</span></tt> for short. Sums and products are exact as long as the absolute value of the mantissa is smaller than <tt class="docutils literal"><span class="pre">2^prec</span></tt>. As soon as the mantissa becomes larger than this threshold, we truncate it to have at most  <tt class="docutils literal"><span class="pre">prec</span></tt> bits (the exponent is incremented accordingly to preserve the magnitude of the number), and it is this operation that typically introduces numerical errors. Division is also not generally exact; although we can add and multiply exactly by setting the precision high enough, no precision is high enough to represent for example 1/3 exactly (the same obviously applies for roots, trigonometric functions, etc).</p>
<div class="section">
<h3><a id="decimal-issues" name="decimal-issues">4.2.1&nbsp;&nbsp;&nbsp;Decimal issues</a></h3>
<p>Mpmath uses binary arithmetic internally, while most interaction with the user is done via the decimal number system. Translating between binary and decimal numbers is a somewhat subtle matter; many Python novices run into the following &quot;bug&quot; (addressed in the <a class="reference" href="http://www.python.org/doc/faq/general/#why-are-floating-point-calculations-so-inaccurate">General Python FAQ</a>):</p>
<pre class="literal-block">
&gt;&gt;&gt; 0.1
0.10000000000000001
</pre>
<p>Decimal fractions fall into the category of numbers that generally cannot be represented exactly in binary floating-point form. For example, none of the numbers <tt class="docutils literal"><span class="pre">0.1</span></tt>, <tt class="docutils literal"><span class="pre">0.01</span></tt>, <tt class="docutils literal"><span class="pre">0.001</span></tt> has an exact representation as a binary floating-point number. Although mpmath can approximate decimal fractions with any accuracy, it does not solve this problem for all uses; users who need <em>exact</em> decimal fractions should look at the <tt class="docutils literal"><span class="pre">decimal</span></tt> module in Python's standard library (or perhaps use fractions, which are much faster).</p>
<p>With <tt class="docutils literal"><span class="pre">prec</span></tt> bits of precision, an arbitrary number can be approximated to within <tt class="docutils literal"><span class="pre">2^(-prec)</span></tt>. With <tt class="docutils literal"><span class="pre">dps</span></tt> decimal digits, the corresponding error is <tt class="docutils literal"><span class="pre">10^-dps</span></tt>. The equivalent values for <tt class="docutils literal"><span class="pre">prec</span></tt> and <tt class="docutils literal"><span class="pre">dps</span></tt> are therefore related proportionally via the factor <tt class="docutils literal"><span class="pre">C</span> <span class="pre">=</span> <span class="pre">log(10)/log(2)</span></tt>, or roughly 3.32. For example, the standard (binary) precision in mpmath is 53 bits, which corresponds to a decimal precision of 15.95 digits.</p>
<p>More precisely, mpmath uses the following formulas to translate between <tt class="docutils literal"><span class="pre">prec</span></tt> and <tt class="docutils literal"><span class="pre">dps</span></tt>:</p>
<pre class="literal-block">
dps(prec) = max(1, int(round(int(prec) / C - 1)))

prec(dps) = max(1, int(round((int(dps) + 1) * C)))
</pre>
<p>Note that the dps is set 1 decimal digit lower than the corresponding binary precision. This is done to hide minor rounding errors and artifacts resulting from binary-decimal conversion. As a result, mpmath interprets 53 bits as giving 15 digits of decimal precision, not 16.</p>
<p>The <tt class="docutils literal"><span class="pre">dps</span></tt> value controls the number of digits to display when printing numbers with <tt class="docutils literal"><span class="pre">str</span></tt>, while the decimal precision used by <tt class="docutils literal"><span class="pre">repr</span></tt> is set two or three digits higher. For example, with 15 dps we have:</p>
<pre class="literal-block">
&gt;&gt;&gt; mp.dps = 15
&gt;&gt;&gt; str(pi)
'3.14159265358979'
&gt;&gt;&gt; repr(+pi)
&quot;mpf('3.1415926535897931')&quot;
</pre>
<p>The extra digits in the output from <tt class="docutils literal"><span class="pre">repr</span></tt> ensure that <tt class="docutils literal"><span class="pre">x</span> <span class="pre">==</span> <span class="pre">eval(repr(x))</span></tt> holds, i.e. that numbers can be converted to strings and back losslessly.</p>
<p>It should be noted that precision and accuracy do not always correlate when translating from binary to decimal. As a simple example, the number 0.1 has a decimal precision of 1 digit but is an infinitely accurate representation of 1/10. Conversely, the number <tt class="docutils literal"><span class="pre">2^-50</span></tt> has a binary representation with 1 bit of precision that is infinitely accurate; the same number can actually be represented exactly as a decimal, but doing so requires 35 significant digits:</p>
<pre class="literal-block">
0.00000000000000088817841970012523233890533447265625
</pre>
<p>In fact, all binary floating-point numbers can be represented exactly as decimals (despite the converse not being true), but displaying more than <tt class="docutils literal"><span class="pre">dps</span></tt> digits is usually not useful, since typically only at most <tt class="docutils literal"><span class="pre">dps</span></tt> digits will be correct when the floating-point number is an approximation for some computed quantity.</p>
</div>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id17" id="rounding" name="rounding">4.3&nbsp;&nbsp;&nbsp;Rounding</a></h2>
<p>There are several different strategies for rounding a too large mantissa or a result that cannot at all be represented exactly in binary floating-point form (such as 1/3 or log(2)). Mpmath supports the following rounding modes:</p>
<blockquote>
<table border="1" class="docutils">
<colgroup>
<col width="16%" />
<col width="84%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Name</th>
<th class="head">Direction</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>Floor</td>
<td>Towards negative infinity</td>
</tr>
<tr><td>Ceiling</td>
<td>Towards positive infinity</td>
</tr>
<tr><td>Down</td>
<td>Towards 0</td>
</tr>
<tr><td>Up</td>
<td>Away from 0</td>
</tr>
<tr><td>Nearest</td>
<td>To nearest; to the nearest even number on a tie</td>
</tr>
</tbody>
</table>
</blockquote>
<p>The first four modes are called <em>directed</em> rounding schemes and are useful for implementing interval arithmetic; they are also fast. Rounding to nearest, which mpmath uses by default, is the slowest but most accurate method.</p>
<p>The arithmetic operations <tt class="docutils literal"><span class="pre">+</span></tt>, <tt class="docutils literal"><span class="pre">-</span></tt>, <tt class="docutils literal"><span class="pre">*</span></tt> and <tt class="docutils literal"><span class="pre">/</span></tt> acting on real floating-point numbers always round their results <em>correctly</em> in mpmath; that is, they are guaranteed to give exact results when possible, they always round in the intended direction, and they don't round to a number farther away than necessary. Exponentiation by an integer <em>n</em> preserves directions but may round too far if either the mantissa or <em>n</em> is very large.</p>
<p>Evaluation of transcendental functions (as well as square roots) is generally performed by computing an approximation with finite precision slightly higher than the target precision, and rounding the result. This gives correctly rounded results with a high probability, but can be wrong in exceptional cases.</p>
<p>Rounding for radix conversion is a slightly tricky business. When converting to a binary floating-point number from a decimal string, mpmath writes the number as an exact fraction and performs correct rounding division if the number is of reasonable size (roughly, larger than 10^-100 and smaller than 10^100), guaranteeing correct rounding. If the exponent is enormous, mpmath first performs a floating-point division to reduce it to a manageable size; this can produce a (tiny) rounding error.</p>
<p>When converting from binary to decimal, mpmath first performs an approximate radix conversion with slightly increased precision, then truncates the resulting decimal number to remove long sequences of trailing 0's and 9's, and finally rounds to nearest, rounding up (away from zero) on a tie. The <tt class="docutils literal"><span class="pre">decimal</span></tt> library could be used to provide more control over the rounding in the binary-to-decimal conversion, and mpmath did do radix conversions via <tt class="docutils literal"><span class="pre">decimal</span></tt> in older versions, but this was far too slow compared to using a custom algorithm.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id18" id="exponent-range" name="exponent-range">4.4&nbsp;&nbsp;&nbsp;Exponent range</a></h2>
<p>In hardware floating-point arithmetic, the size of the exponent is restricted to a fixed range: regular Python floats have a range between roughly <tt class="docutils literal"><span class="pre">10^-300</span></tt> and <tt class="docutils literal"><span class="pre">10^300</span></tt>. Mpmath uses arbitrary precision integers for both the mantissa and the exponent, so numbers can be as large in magnitude as permitted by the computer's memory.</p>
<p>Some care may be necessary when working with extremely large numbers. Although standard arithmetic operators are safe, it is for example futile to attempt to compute the exponential function of of <tt class="docutils literal"><span class="pre">10^100000</span></tt>. Mpmath does not complain when asked to perform such a calculation, but instead chugs away on the problem to the best of its ability, assuming that computer resources are infinite. In the worst case, this will be slow and allocate a huge amount of memory; if entirely impossible Python will at some point raise <tt class="docutils literal"><span class="pre">OverflowError:</span> <span class="pre">long</span> <span class="pre">int</span> <span class="pre">too</span> <span class="pre">large</span> <span class="pre">to</span> <span class="pre">convert</span> <span class="pre">to</span> <span class="pre">int</span></tt>.</p>
<p>In some situations, it might be more convenient if mpmath could &quot;round&quot; extremely small numbers to 0 and extremely large numbers to <tt class="docutils literal"><span class="pre">inf</span></tt>, and directly raise an exception or return <tt class="docutils literal"><span class="pre">nan</span></tt> if there is no reasonable chance of finishing a computation. This option is not available, but could be implemented in the future on demand.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id19" id="compatibility" name="compatibility">4.5&nbsp;&nbsp;&nbsp;Compatibility</a></h2>
<p>The floating-point arithmetic provided by processors that conform to the IEEE 754 <em>double precision</em> standard has a precision of 53 bits and rounds to nearest. (Additional precision and rounding modes are available, but regular double precision arithmetic should be the most familiar to Python users, since the Python <tt class="docutils literal"><span class="pre">float</span></tt> type corresponds to an IEEE double with rounding to nearest on most systems.)</p>
<p>This corresponds roughly to a decimal accuracy of 15 digits, and is the default precision used by mpmath. Thus, under normal circumstances, mpmath should produce identical results to Python <tt class="docutils literal"><span class="pre">float</span></tt> operations. This is not always true, mainly due to the simple fact that mpmath is able to produce more accurate results for transcendental functions. Machine floats very close to the exponent limit also round subnormally, meaning that they lose precision (Python may raise an exception instead of rounding a <tt class="docutils literal"><span class="pre">float</span></tt> subnormally).</p>
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id20" id="optimization-tricks" name="optimization-tricks">5&nbsp;&nbsp;&nbsp;Optimization tricks</a></h1>
<p>There are a few tricks that can significantly speed up mpmath code at low to medium precision (up a hundred digits or so):</p>
<ul class="simple">
<li>Repeated type conversions from floats, strings and integers are expensive (exceptions: <tt class="docutils literal"><span class="pre">n/x</span></tt>, <tt class="docutils literal"><span class="pre">n*x</span></tt> and <tt class="docutils literal"><span class="pre">x**n</span></tt> are fast when <tt class="docutils literal"><span class="pre">n</span></tt> is an <tt class="docutils literal"><span class="pre">int</span></tt> and <tt class="docutils literal"><span class="pre">x</span></tt> is an <tt class="docutils literal"><span class="pre">mpf</span></tt>). Numerical constants that are used repeatedly, such as in the body of a function passed to <tt class="docutils literal"><span class="pre">quadts</span></tt>, should be pre-converted to <tt class="docutils literal"><span class="pre">mpf</span></tt> instances.</li>
<li>The JIT compiler <a class="reference" href="http://psyco.sourceforge.net/">psyco</a> fairly consistently speeds up mpmath about 2x.</li>
<li>An additional 2x gain is possible by using the low-level functions in <tt class="docutils literal"><span class="pre">mpmath.lib</span></tt> instead of <tt class="docutils literal"><span class="pre">mpf</span></tt> instances.</li>
<li>Changing the rounding mode to <em>floor</em> can give a slight speedup.</li>
</ul>
<p>Here follows a simple example demonstrating some of these optimizations.</p>
<p>Original algorithm (0.028 seconds):</p>
<pre class="literal-block">
&gt;&gt;&gt; x = mpf(1)
&gt;&gt;&gt; for i in range(1000):
...     x += 0.1
</pre>
<p>Preconverting the float constant (0.0080 seconds):</p>
<pre class="literal-block">
&gt;&gt;&gt; x = mpf(1)
&gt;&gt;&gt; one_tenth = mpf(0.1)
&gt;&gt;&gt; for i in range(1000):
...     x += one_tenth
</pre>
<p>With psyco (0.0036 seconds):</p>
<pre class="literal-block">
&gt;&gt;&gt; import psyco; psyco.full()
&gt;&gt;&gt; x = mpf(1)
&gt;&gt;&gt; one_tenth = mpf(0.1)
&gt;&gt;&gt; for i in range(1000):
...     x += one_tenth
</pre>
<p>With psyco and low-level functions (0.0017 seconds):</p>
<pre class="literal-block">
&gt;&gt;&gt; import psyco; psyco.full()
&gt;&gt;&gt; from mpmath.lib import from_int, from_float, fadd, round_nearest
&gt;&gt;&gt; x = from_int(1)
&gt;&gt;&gt; one_tenth = from_float(0.1)
&gt;&gt;&gt; for i in range(1000):
...     x = fadd(x, one_tenth, 53, round_nearest)
</pre>
<p>The last version is 16.5 times faster than the first (however, this example is extreme; the gain will usually be smaller in realistic calculations).</p>
<p>Many calculations can be done with ordinary floating-point arithmetic, and only in special cases require multiprecision arithmetic (for example to avoid overflows in corner cases). In these situations, it may be possible to write code that uses fast regular floats by default, and automatically (or manually) falls backs to mpmath only when needed. Python's dynamic namespaces and ability to compile code on the fly are helpful. Here is a simple (probably not failsafe) example:</p>
<pre class="literal-block">
&gt;&gt;&gt; import math
&gt;&gt;&gt; import mpmath
&gt;&gt;&gt;
&gt;&gt;&gt; def evalmath(expr):
...     try:
...         r = eval(expr, math.__dict__)
...     except OverflowError:
...         r = eval(expr, mpmath.__dict__)
...         try:
...             r = float(r)
...         except OverflowError:
...             pass
...     return r
...
&gt;&gt;&gt; evalmath('sin(3)')
0.14112000805986721
&gt;&gt;&gt;
&gt;&gt;&gt; evalmath('exp(10000)')
mpf('8.8068182256629216e+4342')
&gt;&gt;&gt;
&gt;&gt;&gt; evalmath('exp(10000) / exp(10000)')
1.0
</pre>
</div>
</div>

<!-- Generate pageview statistics when this document is viewed on the mpmath website -->
<script src="http://www.google-analytics.com/urchin.js" type="text/javascript"></script>
<script type="text/javascript">

if ((""+document.location).match("google"))
{
    _uacct = "UA-2697185-2";
    urchinTracker();
}
</script>
</body>
</html>
